{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nefario7/cmu-deeplearning/blob/working-hw3/Homework%203/HW3P2_Skip.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "f_fwJWcpqJDR"
      },
      "source": [
        "# Prelimilaries and Kaggle Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TbAnqEppm6MK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9bd52273-685f-4fdb-c805-dde3f88e8868"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Mount Google Drive on Ubuntu (via FUSE)\n",
            " More info: https://launchpad.net/~alessandro-strada/+archive/ubuntu/ppa\n",
            "Press [ENTER] to continue or Ctrl-c to cancel adding it.\n",
            "\n",
            "Get:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:3 http://ppa.launchpad.net/alessandro-strada/ppa/ubuntu bionic InRelease [15.4 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release [696 B]\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Get:8 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release.gpg [836 B]\n",
            "Hit:9 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:10 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [80.8 kB]\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Get:12 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:14 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [950 kB]\n",
            "Hit:15 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:16 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Get:17 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease [15.9 kB]\n",
            "Get:18 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,486 kB]\n",
            "Get:19 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease [21.3 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,132 kB]\n",
            "Get:21 http://ppa.launchpad.net/alessandro-strada/ppa/ubuntu bionic/main amd64 Packages [1,343 B]\n",
            "Get:22 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [884 kB]\n",
            "Get:23 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,693 kB]\n",
            "Get:24 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [1,830 kB]\n",
            "Get:25 http://archive.ubuntu.com/ubuntu bionic-updates/multiverse amd64 Packages [29.8 kB]\n",
            "Get:26 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,264 kB]\n",
            "Get:27 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [918 kB]\n",
            "Get:28 http://archive.ubuntu.com/ubuntu bionic-backports/universe amd64 Packages [12.9 kB]\n",
            "Get:29 http://archive.ubuntu.com/ubuntu bionic-backports/main amd64 Packages [12.2 kB]\n",
            "Get:30 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [937 kB]\n",
            "Get:31 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic/main amd64 Packages [45.3 kB]\n",
            "Get:32 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic/main amd64 Packages [44.3 kB]\n",
            "Fetched 15.6 MB in 7s (2,150 kB/s)\n",
            "Reading package lists... Done\n",
            "Hit:1 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease\n",
            "Ign:2 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:3 http://security.ubuntu.com/ubuntu bionic-security InRelease\n",
            "Hit:4 http://ppa.launchpad.net/alessandro-strada/ppa/ubuntu bionic InRelease\n",
            "Ign:5 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Hit:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Release\n",
            "Hit:7 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:8 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Hit:9 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic-updates InRelease\n",
            "Hit:11 http://archive.ubuntu.com/ubuntu bionic-backports InRelease\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "82 packages can be upgraded. Run 'apt list --upgradable' to see them.\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  google-drive-ocamlfuse\n",
            "0 upgraded, 1 newly installed, 0 to remove and 82 not upgraded.\n",
            "Need to get 1,330 kB of archives.\n",
            "After this operation, 7,023 kB of additional disk space will be used.\n",
            "Get:1 http://ppa.launchpad.net/alessandro-strada/ppa/ubuntu bionic/main amd64 google-drive-ocamlfuse amd64 0.7.27-0ubuntu1~ubuntu18.04.1 [1,330 kB]\n",
            "Fetched 1,330 kB in 2s (863 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 1.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package google-drive-ocamlfuse.\n",
            "(Reading database ... 156210 files and directories currently installed.)\n",
            "Preparing to unpack .../google-drive-ocamlfuse_0.7.27-0ubuntu1~ubuntu18.04.1_amd64.deb ...\n",
            "Unpacking google-drive-ocamlfuse (0.7.27-0ubuntu1~ubuntu18.04.1) ...\n",
            "Setting up google-drive-ocamlfuse (0.7.27-0ubuntu1~ubuntu18.04.1) ...\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: www-browser: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: links2: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: elinks: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: links: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: lynx: not found\n",
            "/usr/bin/xdg-open: 851: /usr/bin/xdg-open: w3m: not found\n",
            "xdg-open: no method available for opening 'https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=F4m7Ld7h7oEZRhvj1Aojt%2F-vDivkLyugxvf6DjG0AL0'\n",
            "/bin/sh: 1: firefox: not found\n",
            "/bin/sh: 1: google-chrome: not found\n",
            "/bin/sh: 1: chromium-browser: not found\n",
            "/bin/sh: 1: open: not found\n",
            "Cannot retrieve auth tokens.\n",
            "Failure(\"Error opening URL:https://accounts.google.com/o/oauth2/auth?client_id=564921029129.apps.googleusercontent.com&redirect_uri=https%3A%2F%2Fgd-ocaml-auth.appspot.com%2Foauth2callback&scope=https%3A%2F%2Fwww.googleapis.com%2Fauth%2Fdrive&response_type=code&access_type=offline&approval_prompt=force&state=F4m7Ld7h7oEZRhvj1Aojt%2F-vDivkLyugxvf6DjG0AL0\")\n"
          ]
        }
      ],
      "source": [
        "from IPython.display import clear_output \n",
        "# NOTWORKING\n",
        "# ! apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "# ! add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "# ! apt-get update -qq 2>&1 > /dev/null\n",
        "# ! apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "\n",
        "# from google.colab import auth\n",
        "# import getpass\n",
        "# from oauth2client.client import GoogleCredentials\n",
        "# auth.authenticate_user()\n",
        "# creds = GoogleCredentials.get_application_default()\n",
        "\n",
        "\n",
        "# ! google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "# vcode = getpass.getpass()\n",
        "# ! echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "\n",
        "# WORKING\n",
        "!sudo add-apt-repository ppa:alessandro-strada/ppa\n",
        "!sudo apt update && sudo apt install google-drive-ocamlfuse\n",
        "!google-drive-ocamlfuse"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!sudo apt-get install w3m # to act as web browser \n",
        "!xdg-settings set default-web-browser w3m.desktop # to set default browser \n",
        "\n",
        "% cd /content\n",
        "! mkdir cmudrive\n",
        "% cd ..\n",
        "! google-drive-ocamlfuse /content/cmudrive\n",
        "! pip install kaggle wandb torch-summary\n",
        "! mkdir ~/.kaggle\n",
        "! cp /content/cmudrive/IDL/kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! pip install --upgrade --force-reinstall --no-deps kaggle \n",
        "! kaggle config set -n path -v /content\n",
        "\n",
        "! wandb login 4bdbe9c204105e1264fe3f54df2732fd1fff8040\n",
        "\n",
        "clear_output()"
      ],
      "metadata": {
        "id": "LfcjHRWK0ncO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZCQtZtkaTrcn"
      },
      "outputs": [],
      "source": [
        "!pip install python-Levenshtein\n",
        "!pip install torchsummaryX # We also install a summary package to check our model's forward before training\n",
        "!git clone --recursive https://github.com/parlance/ctcdecode.git\n",
        "!pip install wget\n",
        "!pip install adamp\n",
        "%cd ctcdecode\n",
        "!pip install .\n",
        "%cd ..\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7AUGUa8tnFhM"
      },
      "outputs": [],
      "source": [
        "! kaggle competitions download -c 11-785-s22-hw3p2\n",
        "\n",
        "! unzip -q /content/competitions/11-785-s22-hw3p2/11-785-s22-hw3p2.zip -d /content\n",
        "! mv /content/hw3p2_student_data/hw3p2_student_data /content/speech_data\n",
        "! rm -rf /content/hw3p2_student_data\n",
        "\n",
        "clear_output()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z4vZbDmJvMp1"
      },
      "source": [
        "# Dependencies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qI4qfx7tiBZt",
        "outputId": "27aa7413-da1b-4de6-d76f-8fb126222ff6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device:  cuda\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torchaudio.transforms as taf\n",
        "from torchsummaryX import summary\n",
        "# from torchsummary import summary\n",
        "\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pad_sequence, pack_padded_sequence, pad_packed_sequence\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from torch.optim.lr_scheduler import ExponentialLR, ReduceLROnPlateau\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "import gc\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import os\n",
        "import csv\n",
        "import yaml\n",
        "import wandb\n",
        "import datetime\n",
        "import time\n",
        "\n",
        "# imports for decoding and distance calculation\n",
        "import ctcdecode\n",
        "import Levenshtein\n",
        "from ctcdecode import CTCBeamDecoder\n",
        "from phonemes import PHONEME_MAP, PHONEMES\n",
        "from adamp import AdamP\n",
        "\n",
        "torch.autograd.set_detect_anomaly(False)\n",
        "torch.autograd.profiler.profile(False)\n",
        "torch.autograd.profiler.emit_nvtx(False)\n",
        "\n",
        "import warnings\n",
        "import multiprocessing\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "print(\"Device: \", DEVICE)\n",
        "\n",
        "def header(head):\n",
        "    print(\"-\"*80)\n",
        "    print(f\"\\t\\t\\t\\t{head.upper()}\")\n",
        "    print(\"-\"*80)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUCKqm1ST1sU"
      },
      "source": [
        "# Dataset and dataloading"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vvUeQsFVsuim"
      },
      "outputs": [],
      "source": [
        "# from phonemes import PHONEME_MAP, PHONEMES\n",
        "# mfcc = \"/content/speech_data/train/mfcc\"\n",
        "# tran = \"/content/speech_data/train/transcript\"\n",
        "# print(len(os.listdir(mfcc)))\n",
        "# for _ in range(1):\n",
        "#     r = np.random.randint(0, 500)\n",
        "\n",
        "#     rfile = os.listdir(mfcc)[r]\n",
        "#     datax = np.load(os.path.join(mfcc, rfile))\n",
        "#     datay = np.load(os.path.join(tran, rfile))\n",
        "#     print(rfile)\n",
        "#     print(datax.shape, datay.shape)\n",
        "#     print(datay[1:-1])\n",
        "#     p = dict(zip(PHONEMES, range(len(PHONEMES))))\n",
        "#     print(p)\n",
        "#     pm = [*map(p.get, datay[1:-1])]\n",
        "#     print([torch.tensor(t) for t in pm])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8SndiVRVqBMa"
      },
      "outputs": [],
      "source": [
        "class LibriSamples(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_path=r\"/content/speech_data\", partition=\"train\"): # You can use partition to specify train or dev\n",
        "        partition_path = os.path.join(data_path, partition)\n",
        "        self.test = True if partition == \"test\" else False\n",
        "\n",
        "        self.X_dir = os.path.join(partition_path, 'mfcc')\n",
        "        self.Y_dir = os.path.join(partition_path, 'transcript')\n",
        "\n",
        "        if self.test:\n",
        "            with open(os.path.join(partition_path, 'test_order.csv'),\"r\") as f:\n",
        "                self.X_files = list(csv.reader(f))[1:]\n",
        "            self.X_data = [np.load(os.path.join(self.X_dir, xfile[0])) for xfile in tqdm(self.X_files, desc=\"Data\", position=0, leave=True)]\n",
        "        else:\n",
        "            self.X_files = os.listdir(self.X_dir)\n",
        "            self.Y_files = os.listdir(self.Y_dir)\n",
        "\n",
        "            self.X_data = [np.load(os.path.join(self.X_dir, xfile)) for xfile in tqdm(self.X_files, desc=\"Data\", position=0, leave=True)]\n",
        "            self.Y_data = [np.load(os.path.join(self.Y_dir, yfile)) for yfile in tqdm(self.Y_files, desc=\"Labels\", position=0, leave=True)]\n",
        "\n",
        "            assert(len(self.X_data) == len(self.Y_data))\n",
        "\n",
        "        self.phonemes = PHONEMES\n",
        "        self.phonemes_idx = dict(zip(PHONEMES, range(len(PHONEMES))))\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.X_files)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        X = self.X_data[idx]\n",
        "        if self.test:\n",
        "            return torch.from_numpy(X)\n",
        "        else:\n",
        "            Y = self.Y_data[idx][1:-1] \n",
        "            Yy = np.array([torch.tensor(self.phonemes_idx[t]) for t in Y])\n",
        "            return torch.from_numpy(X), torch.from_numpy(Yy)\n",
        "    \n",
        "    def collate_fn(self, batch):\n",
        "        if self.test:\n",
        "            batch_x = [x for x in batch]\n",
        "            batch_x_pad = pad_sequence(batch_x, batch_first=True)\n",
        "            lengths_x = [len(x) for x in batch_x]\n",
        "            return batch_x_pad, torch.tensor(lengths_x)\n",
        "        else:\n",
        "            batch_x = [x for x,_ in batch]\n",
        "            batch_y = [y for _,y in batch]\n",
        "            batch_x_pad = pad_sequence(batch_x, batch_first=True)\n",
        "            batch_y_pad = pad_sequence(batch_y, batch_first=True)\n",
        "            lengths_x = [len(x) for x in batch_x]\n",
        "            lengths_y = [len(y) for y in batch_y]\n",
        "            return batch_x_pad, batch_y_pad, torch.tensor(lengths_x), torch.tensor(lengths_y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4mzoYfTKu14s"
      },
      "outputs": [],
      "source": [
        "# batch_size = 64\n",
        "# train_data = LibriSamples(partition='train')\n",
        "# val_data = LibriSamples(partition='dev')\n",
        "# test_data = LibriSamples(partition='test')\n",
        "\n",
        "# train_loader = DataLoader(train_data, batch_size=128, shuffle=True, drop_last=True, collate_fn = train_data.collate_fn, num_workers=2)\n",
        "# val_loader = DataLoader(val_data, batch_size=128, shuffle=False, drop_last=True, collate_fn = val_data.collate_fn, num_workers=2)\n",
        "# test_loader = DataLoader(test_data, batch_size=128, shuffle=False, drop_last=False, collate_fn = test_data.collate_fn)\n",
        "\n",
        "# print(\"Batch size: \", batch_size)\n",
        "# print(\"Train dataset samples = {}, batches = {}\".format(train_data.__len__(), len(train_loader)))\n",
        "# print(\"Val dataset samples = {}, batches = {}\".format(val_data.__len__(), len(val_loader)))\n",
        "# print(\"Test dataset samples = {}, batches = {}\".format(test_data.__len__(), len(test_loader)))\n",
        "\n",
        "# # Test code for checking shapes and return arguments of the train and val loaders"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7NzQ9GPf1wOy"
      },
      "outputs": [],
      "source": [
        "# for data in train_loader:\n",
        "#     x, y, lx, ly = data # if you face an error saying \"Cannot unpack\", then you are not passing the collate_fn argument\n",
        "#     print(x.shape, y.shape, lx.shape, ly.shape)\n",
        "#     print(x[0], lx[0])\n",
        "#     print(y[0], ly[0])\n",
        "#     break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ly4mjUUUuJhy"
      },
      "source": [
        "# Model"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ResNet"
      ],
      "metadata": {
        "id": "yA-6ZrNI_rSi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.nn.modules.conv import Conv1d\n",
        "torch.cuda.empty_cache()\n",
        "class Block(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, stride=1, identity=None):\n",
        "        super(Block, self).__init__()\n",
        "        self.expansion = 4\n",
        "\n",
        "        self.conv1 = nn.Conv1d(in_channels, out_channels, kernel_size=1, stride=1, padding=0)\n",
        "        self.bn1 = nn.BatchNorm1d(out_channels)\n",
        "        self.conv2 = nn.Conv1d(out_channels, out_channels, kernel_size=3, stride=stride, padding=1)\n",
        "        self.bn2 = nn.BatchNorm1d(out_channels)\n",
        "        self.conv3 = nn.Conv1d(out_channels, out_channels * self.expansion, kernel_size=1, stride=1, padding=0)\n",
        "        self.bn3 = nn.BatchNorm1d(out_channels * self.expansion)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "        self.identity_downsample = nn.Sequential(\n",
        "                nn.Conv1d(in_channels, out_channels * self.expansion, kernel_size=1),\n",
        "                nn.BatchNorm1d(out_channels * self.expansion)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        identity = x\n",
        "        identity = self.identity_downsample(identity)\n",
        "\n",
        "        x = self.conv1(x)\n",
        "        x = self.bn1(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.bn2(x)\n",
        "        x = self.relu(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.bn3(x)\n",
        "        \n",
        "        x += identity\n",
        "        x = self.relu(x)\n",
        "        return x\n",
        "\n",
        "class ResNet(nn.Module): # [3, 4, 6]\n",
        "    def __init__(self, layers: list):\n",
        "        super(ResNet, self).__init__()\n",
        "        self.in_channels = 64\n",
        "        self.out_channels = 64\n",
        "        self.stem = nn.Sequential(\n",
        "            nn.Conv1d(13, self.in_channels, kernel_size=7, stride=2, padding=3),\n",
        "            nn.BatchNorm1d(64),\n",
        "            nn.ReLU(),\n",
        "            nn.MaxPool1d(kernel_size=3, stride=2, padding=1)\n",
        "        )\n",
        "\n",
        "        self.block = Block(self.in_channels, self.out_channels, stride=1)\n",
        "        # self.resnet1 = self._make_layers(num_blocks=layers[0], out_channels=64, stride=1)\n",
        "        # self.resnet2 = self._make_layers(num_blocks=layers[1], out_channels=128, stride=2)\n",
        "        # self.resnet3 = self._make_layers(num_blocks=layers[2], out_channels=256, stride=2)\n",
        "        # self.resnet4 = self._make_layers(num_blocks=layers[3], out_channels=512, stride=2)\n",
        "\n",
        "    def _make_layers(self, num_blocks, out_channels, stride):\n",
        "        identity_down = None\n",
        "        layers = []\n",
        "        if stride != 1 or self.in_channels != out_channels * 4:\n",
        "            identity_down = nn.Sequential(\n",
        "                nn.Conv1d(self.in_channels, out_channels * 4, kernel_size=1),\n",
        "                nn.BatchNorm1d(out_channels * 4)\n",
        "            )\n",
        "\n",
        "        layers.append(Block(self.in_channels, out_channels, stride, identity_down))\n",
        "        self.in_channels = out_channels*4\n",
        "\n",
        "        for i in range(num_blocks - 1):\n",
        "            layers.append(Block(self.in_channels, out_channels))\n",
        "\n",
        "        return nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.stem(x)\n",
        "        x = self.block(x)\n",
        "        # x = self.resnet1(x)\n",
        "        # x = self.resnet2(x)\n",
        "        # x = self.resnet3(x)\n",
        "        # x = self.resnet4(x)\n",
        "\n",
        "        return x "
      ],
      "metadata": {
        "id": "5FgP7eJD8fdh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### ASRNet"
      ],
      "metadata": {
        "id": "bC78fom2_tfD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SpeechNet(nn.Module):\n",
        "    def __init__(self, config): # You can add any extra arguments as you wish\n",
        "        super().__init__()\n",
        "        lstm_params = config['arch']\n",
        "        vocab_size = len(PHONEMES)\n",
        "\n",
        "        self.stride = 1\n",
        "        self.skip = lstm_params['skip_connect']\n",
        "\n",
        "        # Embedding\n",
        "        embeddings = lstm_params['embedding_size']\n",
        "        embedding_layers = []\n",
        "        for i in range(len(embeddings) - 1):\n",
        "            conv_params = lstm_params['embedding_args'][i]\n",
        "            embedding_layers.append(nn.Conv1d(embeddings[i], embeddings[i+1], **conv_params))\n",
        "            embedding_layers.append(nn.BatchNorm1d(embeddings[i+1]))\n",
        "            if self.skip:\n",
        "                if i != len(embeddings) - 2:\n",
        "                    embedding_layers.append(nn.ReLU())\n",
        "            else:\n",
        "                embedding_layers.append(nn.ReLU())\n",
        "            # Maybe add a Pooling\n",
        "        self.embeddings = nn.Sequential(*embedding_layers)\n",
        "        embedding_size = embeddings[-1]\n",
        "\n",
        "        if self.skip:\n",
        "            self.residual = nn.Sequential(\n",
        "                nn.Conv1d(embeddings[0], embeddings[-1], **lstm_params['embedding_args'][1]),\n",
        "                nn.BatchNorm1d(embeddings[-1])\n",
        "            )\n",
        "            self.relu = nn.ReLU()\n",
        "\n",
        "        # Block Embedding\n",
        "        # self.embeddings = nn.Sequential(\n",
        "        #     # nn.Conv1d(13, 64, kernel_size=5, stride=2, padding=2),\n",
        "        #     # nn.BatchNorm1d(64),\n",
        "        #     # nn.ReLU(),\n",
        "        #     # nn.MaxPool1d(kernel_size=3, stride=1, padding=1),\n",
        "        #     nn.Conv1d(64, 64, kernel_size=1, stride=1, padding=0),\n",
        "        #     nn.BatchNorm1d(64),\n",
        "        #     nn.Conv1d(64, 64, kernel_size=3, stride=2, padding=1),\n",
        "        #     nn.BatchNorm1d(64),\n",
        "        #     nn.Conv1d(64, 256, kernel_size=1, stride=1, padding=0),\n",
        "        #     nn.BatchNorm1d(256),\n",
        "        #     nn.ReLU()\n",
        "        # )\n",
        "        # embedding_size = 256\n",
        "\n",
        "        # ResNet Embedding\n",
        "        # self.embeddings = ResNet(layers=[1])\n",
        "        # embedding_size = 256\n",
        "\n",
        "        # RNN Block\n",
        "        if config['rnn'] == 'GRU':\n",
        "            self.lstm = nn.GRU(\n",
        "                input_size=embedding_size,\n",
        "                hidden_size=lstm_params['hidden_size'],\n",
        "                num_layers=lstm_params['num_layers'],\n",
        "                dropout = lstm_params['dropout'],\n",
        "                bidirectional=True,\n",
        "                batch_first=True\n",
        "            )\n",
        "        else:\n",
        "            self.lstm = nn.LSTM(\n",
        "                input_size=embedding_size,\n",
        "                hidden_size=lstm_params['hidden_size'],\n",
        "                num_layers=lstm_params['num_layers'],\n",
        "                dropout = lstm_params['dropout'],\n",
        "                bidirectional=True,\n",
        "                batch_first=True\n",
        "                )\n",
        "\n",
        "        # Classification\n",
        "        self.classification = nn.Sequential(\n",
        "            nn.Linear(lstm_params['hidden_size'] * 2, 2048),\n",
        "            nn.Dropout(p=0.2),\n",
        "            nn.Linear(2048, vocab_size)\n",
        "        )\n",
        "\n",
        "    def forward(self, x, x_len): \n",
        "        x = torch.transpose(x, 1, 2)\n",
        "\n",
        "        if self.skip:\n",
        "            residual = self.residual(x)\n",
        "\n",
        "        x = self.embeddings(x)\n",
        "        if self.skip:\n",
        "            x = x + residual\n",
        "            x = self.relu(x)\n",
        "            \n",
        "        x = torch.transpose(x, 1, 2)\n",
        "\n",
        "        x_len = torch.clamp(x_len, min=0, max=x.shape[1])\n",
        "\n",
        "        packed_input = pack_padded_sequence(x, x_len, enforce_sorted=False, batch_first=True)\n",
        "        out, _ = self.lstm(packed_input)\n",
        "        out, lengths  = pad_packed_sequence(out, batch_first=True)\n",
        "        out = self.classification(out)\n",
        "        out = F.log_softmax(out, dim=2)\n",
        "        return out, lengths\n",
        "\n",
        "    def initialize_weights(self):\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv1d):\n",
        "                nn.init.trunc_normal_(m.weight, std=0.2)\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                nn.init.constant_(m.weight, 1)\n",
        "                nn.init.constant_(m.bias, 0)\n",
        "            elif isinstance(m, nn.Linear):\n",
        "                nn.init.trunc_normal_(m.weight, std=0.2)\n",
        "                nn.init.constant_(m.bias, 0)"
      ],
      "metadata": {
        "id": "Wc2fblIK_vKS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Arch"
      ],
      "metadata": {
        "id": "7yLRX4iwPP90"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGoiXd70tb5z"
      },
      "outputs": [],
      "source": [
        "# class SpeechNet(nn.Module):\n",
        "#     def __init__(self, config): # You can add any extra arguments as you wish\n",
        "#         super().__init__()\n",
        "#         lstm_params = config['arch']\n",
        "#         vocab_size = len(PHONEMES)\n",
        "\n",
        "#         self.stride = 1\n",
        "\n",
        "#         # Embedding\n",
        "#         embeddings = [13] + lstm_params['embedding_size']\n",
        "#         embedding_layers = []\n",
        "#         for i in range(len(embeddings) - 1):\n",
        "#             embedding_layers.append(nn.Conv1d(embeddings[i], embeddings[i+1], kernel_size=3, padding=1))\n",
        "#             embedding_layers.append(nn.BatchNorm1d(embeddings[i+1]))\n",
        "#             embedding_layers.append(nn.ReLU())\n",
        "#             # Maybe add a Pooling\n",
        "#         self.embeddings = nn.Sequential(*embedding_layers)\n",
        "#         embedding_size = embeddings[-1]\n",
        "\n",
        "#         # Block Embedding\n",
        "#         # self.embeddings = nn.Sequential(\n",
        "#         #     # nn.Conv1d(13, 64, kernel_size=5, stride=2, padding=2),\n",
        "#         #     # nn.BatchNorm1d(64),\n",
        "#         #     # nn.ReLU(),\n",
        "#         #     # nn.MaxPool1d(kernel_size=3, stride=1, padding=1),\n",
        "#         #     nn.Conv1d(64, 64, kernel_size=1, stride=1, padding=0),\n",
        "#         #     nn.BatchNorm1d(64),\n",
        "#         #     nn.Conv1d(64, 64, kernel_size=3, stride=2, padding=1),\n",
        "#         #     nn.BatchNorm1d(64),\n",
        "#         #     nn.Conv1d(64, 256, kernel_size=1, stride=1, padding=0),\n",
        "#         #     nn.BatchNorm1d(256),\n",
        "#         #     nn.ReLU()\n",
        "#         # )\n",
        "#         # embedding_size = 256\n",
        "\n",
        "#         # ResNet Embedding\n",
        "#         # self.embeddings = ResNet(layers=[1])\n",
        "#         # embedding_size = 256\n",
        "\n",
        "#         # RNN Block\n",
        "#         if config['rnn'] == 'GRU':\n",
        "#             self.lstm = nn.GRU(\n",
        "#                 input_size=embedding_size,\n",
        "#                 hidden_size=lstm_params['hidden_size'],\n",
        "#                 num_layers=lstm_params['num_layers'],\n",
        "#                 dropout = lstm_params['dropout'],\n",
        "#                 bidirectional=True,\n",
        "#                 batch_first=True\n",
        "#             )\n",
        "#         else:\n",
        "#             self.lstm = nn.LSTM(\n",
        "#                 input_size=embedding_size,\n",
        "#                 hidden_size=lstm_params['hidden_size'],\n",
        "#                 num_layers=lstm_params['num_layers'],\n",
        "#                 dropout = lstm_params['dropout'],\n",
        "#                 bidirectional=True,\n",
        "#                 batch_first=True\n",
        "#                 )\n",
        "\n",
        "#         # Classification\n",
        "#         self.classification = nn.Sequential(\n",
        "#             nn.Linear(lstm_params['hidden_size'] * 2, 2048),\n",
        "#             nn.Dropout(p=0.2),\n",
        "#             nn.Linear(2048, 1024),\n",
        "#             nn.Dropout(p=0.2),\n",
        "#             nn.Linear(1024, vocab_size)\n",
        "#         )\n",
        "\n",
        "#     def forward(self, x, x_len): \n",
        "#         x = torch.transpose(self.embeddings(torch.transpose(x, 1, 2)), 1, 2)\n",
        "#         # x_len = torch.clamp(x_len, min=0, max=x.shape[1])\n",
        "#         packed_input = pack_padded_sequence(x, x_len, enforce_sorted=False, batch_first=True)\n",
        "#         out, _ = self.lstm(packed_input)\n",
        "#         out, lengths  = pad_packed_sequence(out, batch_first=True)\n",
        "#         out = self.classification(out)\n",
        "#         out = F.log_softmax(out, dim=2)\n",
        "#         return out, lengths\n",
        "\n",
        "#     def initialize_weights(self):\n",
        "#         for m in self.modules():\n",
        "#             if isinstance(m, nn.Conv1d):\n",
        "#                 nn.init.trunc_normal_(m.weight, std=0.2)\n",
        "#             elif isinstance(m, nn.BatchNorm2d):\n",
        "#                 nn.init.constant_(m.weight, 1)\n",
        "#                 nn.init.constant_(m.bias, 0)\n",
        "#             elif isinstance(m, nn.Linear):\n",
        "#                 nn.init.trunc_normal_(m.weight, std=0.2)\n",
        "#                 nn.init.constant_(m.bias, 0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uLjmHc4mMyB4"
      },
      "outputs": [],
      "source": [
        "# config = {\n",
        "#     '': 'LSTM-4layer-medium',\n",
        "#     'batch_size': 128,\n",
        "#     'epochs': 100,\n",
        "#     'scheduler': 'CALR',             # CosineAnnealingLR (CALR), ReduceLRonPlateau (RLRP)\n",
        "#     'optimizer': 'AdamP',            # SGD, Adam, AdamW, AdamP\n",
        "#     'rnn': 'LSTM',                   # GRU, LSTM\n",
        "#     'optim': {'lr': 0.002},\n",
        "#     'decoder': {'beam_width': 3, 'cutoff_top_n': 40, 'cutoff_prob': 1.0},\n",
        "#     'arch': {'embedding_size': [64, 256], 'hidden_size': 256, 'num_layers': 4, 'dropout': 0.25},\n",
        "#     'save': True,\n",
        "#     'log': True,\n",
        "#     'randomize': False,\n",
        "# }\n",
        "# model = SpeechNet(config).cuda()\n",
        "# print(model)\n",
        "# # out, out_lengths = model(x.cuda(), lx)\n",
        "# # print(out.shape, out_lengths.shape)\n",
        "# # print(y.shape, ly.shape)\n",
        "# summary(model, x.cuda(), lx)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IBwunYpyugFg"
      },
      "source": [
        "# Training Configuration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "27XuR3frZi79"
      },
      "outputs": [],
      "source": [
        "def convert_to_string(tokens, seq_len, phoneme_map, phonemes):\n",
        "    return \"\".join([phoneme_map[phonemes[x]] for x in tokens[0:seq_len]])\n",
        "\n",
        "def calculate_levenshtein(decoder, h, y, lh, ly):\n",
        "    phoneme_map = dict(zip(PHONEMES, PHONEME_MAP))\n",
        "    batch_size = ly.shape[0]\n",
        "    dist = 0\n",
        "    beam_results, beam_scores, timesteps, out_lens = decoder.decode(h, seq_lens = lh)\n",
        "\n",
        "    for i in range(batch_size): # Loop through each element in the batch\n",
        "        h_string = convert_to_string(beam_results[i][0], out_lens[i][0], phoneme_map, PHONEMES)\n",
        "        y_string = convert_to_string(y[i], ly[i], phoneme_map, PHONEMES)\n",
        "        dist += Levenshtein.distance(h_string, y_string)\n",
        "    dist/=batch_size\n",
        "    return dist"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kzwsqG_eqKMp"
      },
      "outputs": [],
      "source": [
        "class ModelSetup:\n",
        "    def __init__(self, config, save_path):\n",
        "        self.config = config\n",
        "        self.log = config['log']\n",
        "        self.save = config['save']\n",
        "        print(f\"Saving : {self.save} and Logging : {self.log}\")\n",
        "\n",
        "        self.phoneme_map = dict(zip(PHONEMES, PHONEME_MAP))\n",
        "        self.phonemes_ctc = PHONEME_MAP\n",
        "\n",
        "        self.SAVE_DIR = save_path\n",
        "        self.DATA_DIR = r\"/content/speech_data\" \n",
        "\n",
        "    def __gen_model_name(self):\n",
        "        # Generate a model name based on config\n",
        "        save_name = ''\n",
        "\n",
        "        for key, val in self.config.items():\n",
        "            abbr = key[0] if len(key) > 2 else key\n",
        "            if isinstance(val, dict):\n",
        "                data = 'lr' + str(val[\"lr\"])\n",
        "                save_name += data\n",
        "                break\n",
        "            elif key == '':\n",
        "                save_name += abbr + str(val)\n",
        "                for key, val in self.config['arch'].items():\n",
        "                    save_name += '-' + str(val)\n",
        "                save_name += '_'\n",
        "            else:\n",
        "                data = abbr + str(val) + '_'\n",
        "                save_name += data\n",
        "                \n",
        "\n",
        "        if self.config['randomize']:\n",
        "            save_name = save_name + \"-v\" + str(np.random.randint(10, 1000))\n",
        "        print(\"\\nModel Name: \", save_name)\n",
        "        self.model_name = save_name\n",
        "\n",
        "    def __save_model_params(self, continue_train):\n",
        "        # Create Model Directory\n",
        "        save_path = os.path.join(self.SAVE_DIR, self.model_name)\n",
        "        if not continue_train:\n",
        "            try:\n",
        "                os.mkdir(save_path)\n",
        "            except FileExistsError:\n",
        "                d = input(\"Model name already exists. Delete existing model? (y/n)\")\n",
        "                if d == 'y':\n",
        "                    import shutil\n",
        "                    shutil.rmtree(save_path)\n",
        "                    os.mkdir(save_path)\n",
        "                else:\n",
        "                    print(\"Exiting!\")\n",
        "                    exit(0)\n",
        "                    return None\n",
        "\n",
        "            os.mkdir(os.path.join(save_path, 'Checkpoints'))\n",
        "            # Saving Model Configuration\n",
        "            with open(os.path.join(save_path, 'model_config.yaml'), 'w') as metadata:\n",
        "                yaml.dump({'Experiment': self.config['']}, metadata, indent=4, default_flow_style=False)\n",
        "                yaml.dump(self.config, metadata, indent=4, default_flow_style=False)\n",
        "            print(\"Model to be saved at: \", save_path)\n",
        "            self.model_path = save_path\n",
        "\n",
        "    def dataloaders(self): \n",
        "        # self.train_transforms = [\n",
        "        #                          taf.TimeMasking(10, p=0.25),\n",
        "        #                          taf.FrequencyMasking(1)\n",
        "\n",
        "        # ]\n",
        "        # self.val_transforms = []\n",
        "        self.train_data = LibriSamples(partition='train')\n",
        "        self.val_data = LibriSamples(partition='dev')\n",
        "\n",
        "        self.train_loader = DataLoader(\n",
        "            self.train_data, \n",
        "            batch_size=self.config['batch_size'], \n",
        "            shuffle=True, \n",
        "            drop_last=True, \n",
        "            collate_fn = self.train_data.collate_fn, \n",
        "            num_workers=2,\n",
        "            pin_memory=True) \n",
        "        self.val_loader = DataLoader(\n",
        "            self.val_data, \n",
        "            batch_size=self.config['batch_size'], \n",
        "            shuffle=False, \n",
        "            drop_last=True, \n",
        "            collate_fn = self.val_data.collate_fn, \n",
        "            num_workers=2)\n",
        "\n",
        "    def save_checkpoint(self, epoch, model, optimizer, loss):\n",
        "        print(\"Saving Checkpoint!\")\n",
        "        torch.save({\n",
        "            'epoch': epoch,\n",
        "            'model_state_dict': model.state_dict(),\n",
        "            'optimizer_state_dict': optimizer.state_dict(),\n",
        "            'loss': loss\n",
        "            }, os.path.join(self.model_path, 'Checkpoints', 'chkpt_' + str(epoch) + '.pth'))\n",
        "\n",
        "    def save_model(self, epoch=None, onnx=False):\n",
        "        print(\"Saving Model!\")\n",
        "        try:\n",
        "            if not self.save:\n",
        "                self.__save_model_params()\n",
        "            if epoch is None:\n",
        "                name = os.path.join(self.model_path, \"model_\" + str(epoch) + \".pth\")\n",
        "            else:\n",
        "                name = os.path.join(self.model_path, \"model\" + \".pth\")\n",
        "            torch.save(self.model.state_dict(), name)\n",
        "            if onnx:\n",
        "                torch.onnx.export(self.model, name.split('.')[0] + '.onnx')\n",
        "                wandb.save(name.split('.')[0] + '.onnx')\n",
        "        except:\n",
        "            print(\"Model couldn't be saved!\")\n",
        "\n",
        "    def setup(self, continue_train=False, chkpt=None):\n",
        "        header(\"Model Setup\")\n",
        "\n",
        "        # Model\n",
        "        self.model = SpeechNet(self.config).cuda()\n",
        "        summary(self.model, torch.randn(128, 1692, 13).cuda(), torch.tensor([128]))\n",
        "        self.__gen_model_name()\n",
        "        if self.save: self.__save_model_params(continue_train)\n",
        "\n",
        "        # Loss\n",
        "        self.criterion = nn.CTCLoss()\n",
        "\n",
        "        # Decoder\n",
        "        self.decoder = CTCBeamDecoder(\n",
        "                self.phonemes_ctc,\n",
        "                blank_id=0,\n",
        "                log_probs_input=True,\n",
        "                **self.config['decoder']\n",
        "        )\n",
        "        \n",
        "        # Optimizer\n",
        "        if self.config[\"optimizer\"] == 'SGD':\n",
        "            self.optimizer = optim.SGD(self.model.parameters(), **self.config['optim'])\n",
        "        elif self.config[\"optimizer\"] == \"Adam\":\n",
        "            self.optimizer = optim.Adam(self.model.parameters(), **self.config['optim'])\n",
        "        elif self.config[\"optimizer\"] == \"AdamW\":\n",
        "            self.optimizer = optim.AdamW(self.model.parameters(), **self.config['optim'])\n",
        "        elif self.config[\"optimizer\"] == \"AdamP\":\n",
        "            self.optimizer = AdamP(self.model.parameters(), **self.config['optim'])\n",
        "\n",
        "        self.chkpt = 0\n",
        "        if continue_train:\n",
        "            self.chkpt = chkpt\n",
        "            assert chkpt is not None\n",
        "\n",
        "            chkpt_path = os.path.join(self.model_path, 'Checkpoints', 'chkpt_' + str(chkpt) + '.pth')\n",
        "            try:\n",
        "                checkpoint = torch.load(chkpt_path)\n",
        "            except FileNotFoundError:\n",
        "                print(\"Checkpoint not found in the directory!\")\n",
        "                print(\"Incorrect: \", chkpt_path)\n",
        "\n",
        "            self.model.load_state_dict(checkpoint['model_state_dict'])\n",
        "            self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "\n",
        "        # Scheduler\n",
        "        if self.config[\"scheduler\"] == 'CALR':\n",
        "            self.scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=(len(self.train_loader) * self.config['epochs']))\n",
        "        elif self.config[\"scheduler\"] == 'RLRP':\n",
        "            self.scheduler = optim.lr_scheduler.ReduceLROnPlateau(\n",
        "                self.optimizer, \n",
        "                mode='min', \n",
        "                factor=0.5, \n",
        "                patience=15,\n",
        "                threshold=0.25,\n",
        "                cooldown=15)\n",
        "        elif self.config[\"scheduler\"] == None:\n",
        "            pass\n",
        "\n",
        "        self.scaler = torch.cuda.amp.GradScaler()\n",
        "    \n",
        "    def train(self, continue_train=False, save_freq=2):\n",
        "        header(\"Training\")\n",
        "        epochs = self.config['epochs'] - self.chkpt\n",
        "        batch_size = self.config['batch_size']\n",
        "\n",
        "        if self.log:\n",
        "            wandb.init(project=\"hw3-chinmay\", entity=\"dl-study-group\", config=self.config) #, name=self.config['']\n",
        "            wandb.watch(self.model, criterion=self.criterion, log=\"all\", log_freq=batch_size, idx=None)\n",
        "\n",
        "        delta_time = datetime.timedelta(seconds = 0)\n",
        "        for epoch in range(epochs):\n",
        "            start_time = time.time()\n",
        "\n",
        "            self.model.train()\n",
        "            print(\"\\nEpoch-\", epoch + 1)\n",
        "            batch_bar = tqdm(total=len(self.train_loader), dynamic_ncols=True, leave=False, position=0, desc='Train') \n",
        "            total_loss = 0\n",
        "\n",
        "            for i, data in enumerate(self.train_loader, 0):\n",
        "                torch.cuda.empty_cache()\n",
        "                self.optimizer.zero_grad()\n",
        "\n",
        "                x, y, x_len, y_len = data\n",
        "                x = x.cuda()\n",
        "                y = y.cuda()\n",
        "\n",
        "                with torch.cuda.amp.autocast():    \n",
        "                    output, output_len = self.model(x, x_len)    # B x T x 41\n",
        "                    output_transposed = torch.transpose(output, 0, 1)              # T x B x 41\n",
        "                    loss = self.criterion(output_transposed, y, output_len, y_len)\n",
        "\n",
        "                total_loss += loss.item()\n",
        "                batch_bar.set_postfix(\n",
        "                    loss=\"{:.04f}\".format(float(total_loss / (i + 1))),\n",
        "                    lr=\"{:.04f}\".format(float(self.optimizer.param_groups[0]['lr']))\n",
        "                    )\n",
        "                self.scaler.scale(loss).backward() \n",
        "                self.scaler.step(self.optimizer)\n",
        "                self.scaler.update()\n",
        "                if self.config[\"scheduler\"] == 'CALR': self.scheduler.step()\n",
        "                batch_bar.update()\n",
        "  \n",
        "            batch_bar.close()\n",
        "            trainlos = float(total_loss / len(self.train_loader))\n",
        "            trainlra = float(self.optimizer.param_groups[0]['lr'])\n",
        "            print(f\"Epoch {epoch + 1}/{epochs} | Train Loss {trainlos:.04f} | Learning Rate {trainlra:.04f}\")\n",
        "\n",
        "            if self.log:\n",
        "                    wandb.log({\"Training Loss\": trainlos, \"Learning Rate\": trainlra})\n",
        "                    \n",
        "            lev = self.validate()\n",
        "            if self.config[\"scheduler\"] == 'RLRP': self.scheduler.step(lev)\n",
        "\n",
        "            delta_time += datetime.timedelta(seconds = (time.time() - start_time))\n",
        "            time_lapsed = delta_time\n",
        "            time_left = delta_time * (epochs - epoch - 1) / (epoch + 1)\n",
        "            print(f\"Time lapsed = {str(time_lapsed)}\")\n",
        "            print(f\"Time left = {str(time_left)}\")\n",
        "\n",
        "            if self.save:\n",
        "                # Save Model\n",
        "                if epoch % save_freq == 0: self.save_model(epoch)\n",
        "                # Save Checkpoint\n",
        "                self.save_checkpoint(epoch + self.chkpt + 1, self.model, self.optimizer, total_loss / len(self.train_loader))\n",
        "        \n",
        "    def validate(self):\n",
        "        self.model.eval()\n",
        "        batch_bar = tqdm(total=len(self.val_loader), position=0, leave=False, desc='Val')\n",
        "        total_levenshtein = 0\n",
        "        for i, data in enumerate(self.val_loader, 0):\n",
        "            x, y, x_len, y_len = data\n",
        "            x = x.cuda()\n",
        "            y = y.cuda()\n",
        "\n",
        "            with torch.no_grad():    \n",
        "                output, output_len = self.model(x, x_len)\n",
        "\n",
        "            total_levenshtein += calculate_levenshtein(self.decoder, output, y, output_len, y_len)\n",
        "            \n",
        "            batch_bar.set_postfix(LD=\"{:.04f}\".format(float(total_levenshtein / (i + 1))))\n",
        "            batch_bar.update()\n",
        "\n",
        "        batch_bar.close()\n",
        "        val_lev = float(total_levenshtein / len(self.val_loader))\n",
        "        print(\"\\nValidation LD: {:.04f}\".format(val_lev))\n",
        "        if self.log:\n",
        "            wandb.log({\"Validation LD\": val_lev})\n",
        "\n",
        "        return val_lev"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "72yaABA_w8kt"
      },
      "source": [
        "# Hyperparameters and Run"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qSW09tgXxERy",
        "outputId": "80a2c2fd-3cfb-4ad7-fcc4-e3ecf1fdcbc6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving : True and Logging : True\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Data: 100%|| 28539/28539 [00:18<00:00, 1547.81it/s]\n",
            "Labels: 100%|| 28539/28539 [00:08<00:00, 3496.15it/s]\n",
            "Data: 100%|| 2703/2703 [00:00<00:00, 3082.67it/s]\n",
            "Labels: 100%|| 2703/2703 [00:00<00:00, 3842.16it/s]\n"
          ]
        }
      ],
      "source": [
        "#Next experiment with RLRP (cooldown 8-10)\n",
        "config = {\n",
        "    '': 'LSTM-5layer-medium3-skip',\n",
        "    'batch_size': 128,\n",
        "    'epochs': 100,\n",
        "    'scheduler': 'RLRP',             # CosineAnnealingLR (CALR), ReduceLRonPlateau (RLRP)\n",
        "    'optimizer': 'AdamP',            # SGD, Adam, AdamW, AdamP\n",
        "    'rnn': 'LSTM',                   # GRU, LSTM\n",
        "    'optim': {'lr': 0.002},\n",
        "    'decoder': {'beam_width': 3, 'cutoff_top_n': 40, 'cutoff_prob': 1.0},\n",
        "    'arch': {\n",
        "        'embedding_size': [13, 64, 128, 256], \n",
        "        'embedding_args': [\n",
        "                           {'kernel_size':1, 'stride':1, 'padding':0},\n",
        "                           {'kernel_size':3, 'stride':2, 'padding':1},\n",
        "                           {'kernel_size':1, 'stride':1, 'padding':0},\n",
        "                           ], \n",
        "        'skip_connect': True,\n",
        "        'hidden_size': 256, \n",
        "        'num_layers': 5, \n",
        "        'dropout':0.25},\n",
        "    'save': True,\n",
        "    'log': True,\n",
        "    'randomize': False,\n",
        "}\n",
        "\n",
        "# SpeechNet\n",
        "folder_path = r'/content/cmudrive/IDL/hw3-ablations'\n",
        "asr = ModelSetup(config, save_path = folder_path)\n",
        "asr.dataloaders()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O9ovFakK8IGy",
        "outputId": "c9bebb2f-352e-4693-da8c-734590dd0321"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "\t\t\t\tMODEL SETUP\n",
            "--------------------------------------------------------------------------------\n",
            "==================================================================================\n",
            "                              Kernel Shape     Output Shape     Params  \\\n",
            "Layer                                                                    \n",
            "0_residual.Conv1d_0           [13, 256, 3]  [128, 256, 846]     10.24k   \n",
            "1_residual.BatchNorm1d_1             [256]  [128, 256, 846]      512.0   \n",
            "2_embeddings.Conv1d_0          [13, 64, 1]  [128, 64, 1692]      896.0   \n",
            "3_embeddings.BatchNorm1d_1            [64]  [128, 64, 1692]      128.0   \n",
            "4_embeddings.ReLU_2                      -  [128, 64, 1692]          -   \n",
            "5_embeddings.Conv1d_3         [64, 128, 3]  [128, 128, 846]    24.704k   \n",
            "6_embeddings.BatchNorm1d_4           [128]  [128, 128, 846]      256.0   \n",
            "7_embeddings.ReLU_5                      -  [128, 128, 846]          -   \n",
            "8_embeddings.Conv1d_6        [128, 256, 1]  [128, 256, 846]    33.024k   \n",
            "9_embeddings.BatchNorm1d_7           [256]  [128, 256, 846]      512.0   \n",
            "10_relu                                  -  [128, 256, 846]          -   \n",
            "11_lstm                                  -       [128, 512]  7.360512M   \n",
            "12_classification.Linear_0     [512, 2048]   [1, 128, 2048]  1.050624M   \n",
            "13_classification.Dropout_1              -   [1, 128, 2048]          -   \n",
            "14_classification.Linear_2      [2048, 41]     [1, 128, 41]    84.009k   \n",
            "\n",
            "                              Mult-Adds  \n",
            "Layer                                    \n",
            "0_residual.Conv1d_0           8.446464M  \n",
            "1_residual.BatchNorm1d_1          256.0  \n",
            "2_embeddings.Conv1d_0         1.407744M  \n",
            "3_embeddings.BatchNorm1d_1         64.0  \n",
            "4_embeddings.ReLU_2                   -  \n",
            "5_embeddings.Conv1d_3        20.791296M  \n",
            "6_embeddings.BatchNorm1d_4        128.0  \n",
            "7_embeddings.ReLU_5                   -  \n",
            "8_embeddings.Conv1d_6        27.721728M  \n",
            "9_embeddings.BatchNorm1d_7        256.0  \n",
            "10_relu                               -  \n",
            "11_lstm                       7.340032M  \n",
            "12_classification.Linear_0    1.048576M  \n",
            "13_classification.Dropout_1           -  \n",
            "14_classification.Linear_2      83.968k  \n",
            "----------------------------------------------------------------------------------\n",
            "                          Totals\n",
            "Total params           8.565417M\n",
            "Trainable params       8.565417M\n",
            "Non-trainable params         0.0\n",
            "Mult-Adds             66.840512M\n",
            "==================================================================================\n",
            "\n",
            "Model Name:  LSTM-5layer-medium3-skip-[13, 64, 128, 256]-[{'kernel_size': 1, 'stride': 1, 'padding': 0}, {'kernel_size': 3, 'stride': 2, 'padding': 1}, {'kernel_size': 1, 'stride': 1, 'padding': 0}]-True-256-5-0.25_b128_e100_sRLRP_oAdamP_rLSTM_lr0.002\n",
            "Model to be saved at:  /content/cmudrive/IDL/hw3-ablations/LSTM-5layer-medium3-skip-[13, 64, 128, 256]-[{'kernel_size': 1, 'stride': 1, 'padding': 0}, {'kernel_size': 3, 'stride': 2, 'padding': 1}, {'kernel_size': 1, 'stride': 1, 'padding': 0}]-True-256-5-0.25_b128_e100_sRLRP_oAdamP_rLSTM_lr0.002\n"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "asr.setup()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "MG4F77Nm0Am9",
        "outputId": "2857572a-54b4-4152-f191-bc0e8b9f8b42"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------------------------------------\n",
            "\t\t\t\tTRAINING\n",
            "--------------------------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnefario7\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.12.11"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/wandb/run-20220403_054051-27ihl6q6</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Syncing run <strong><a href=\"https://wandb.ai/dl-study-group/hw3-chinmay/runs/27ihl6q6\" target=\"_blank\">lively-shadow-10</a></strong> to <a href=\"https://wandb.ai/dl-study-group/hw3-chinmay\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Epoch- 1\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100 | Train Loss 3.8423 | Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 72.2113\n",
            "Time lapsed = 0:04:15.228249\n",
            "Time left = 7:01:07.596651\n",
            "Saving Model!\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 2\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 2/100 | Train Loss 2.2265 | Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 26.4900\n",
            "Time lapsed = 0:08:36.111489\n",
            "Time left = 7:01:29.462961\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 3\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 3/100 | Train Loss 0.8571 | Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 16.9881\n",
            "Time lapsed = 0:12:57.167569\n",
            "Time left = 6:58:48.418064\n",
            "Saving Model!\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 4\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 4/100 | Train Loss 0.5979 | Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 13.5290\n",
            "Time lapsed = 0:17:18.656344\n",
            "Time left = 6:55:27.752256\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 5\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 5/100 | Train Loss 0.4910 | Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 11.9498\n",
            "Time lapsed = 0:21:40.200083\n",
            "Time left = 6:51:43.801577\n",
            "Saving Model!\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 6\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 6/100 | Train Loss 0.4306 | Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 11.0060\n",
            "Time lapsed = 0:26:01.019455\n",
            "Time left = 6:47:35.971462\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 7\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 7/100 | Train Loss 0.3864 | Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 10.1581\n",
            "Time lapsed = 0:30:21.830407\n",
            "Time left = 6:43:24.318264\n",
            "Saving Model!\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 8\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 8/100 | Train Loss 0.3478 | Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 9.7195\n",
            "Time lapsed = 0:34:42.556023\n",
            "Time left = 6:39:09.394264\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 9\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 9/100 | Train Loss 0.3231 | Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 9.5610\n",
            "Time lapsed = 0:39:03.473163\n",
            "Time left = 6:34:55.117537\n",
            "Saving Model!\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100 | Train Loss 0.2992 | Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 9.1704\n",
            "Time lapsed = 0:43:23.864538\n",
            "Time left = 6:30:34.780842\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 11\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 11/100 | Train Loss 0.2784 | Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 8.8337\n",
            "Time lapsed = 0:47:44.878655\n",
            "Time left = 6:26:19.472754\n",
            "Saving Model!\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 12\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 12/100 | Train Loss 0.2657 | Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 9.2106\n",
            "Time lapsed = 0:52:05.987321\n",
            "Time left = 6:22:03.907021\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 13\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 13/100 | Train Loss 0.2528 | Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 8.9159\n",
            "Time lapsed = 0:56:26.651164\n",
            "Time left = 6:17:44.511636\n",
            "Saving Model!\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 14\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 14/100 | Train Loss 0.2394 | Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 8.4959\n",
            "Time lapsed = 1:00:47.412855\n",
            "Time left = 6:13:25.536109\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 15\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 15/100 | Train Loss 0.2303 | Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 8.1957\n",
            "Time lapsed = 1:05:08.424690\n",
            "Time left = 6:09:07.739910\n",
            "Saving Model!\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 16\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 16/100 | Train Loss 0.2159 | Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 8.2273\n",
            "Time lapsed = 1:09:29.448131\n",
            "Time left = 6:04:49.602688\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 17\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 17/100 | Train Loss 0.2100 | Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 8.1648\n",
            "Time lapsed = 1:13:50.694551\n",
            "Time left = 6:00:32.214573\n",
            "Saving Model!\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 18\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 18/100 | Train Loss 0.1995 | Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 8.0811\n",
            "Time lapsed = 1:18:11.735190\n",
            "Time left = 5:56:13.460310\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 19\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 19/100 | Train Loss 0.1915 | Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 7.8538\n",
            "Time lapsed = 1:22:32.731383\n",
            "Time left = 5:51:54.275896\n",
            "Saving Model!\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 20\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 20/100 | Train Loss 0.1864 | Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 7.9680\n",
            "Time lapsed = 1:26:53.627001\n",
            "Time left = 5:47:34.508004\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 21\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 21/100 | Train Loss 0.1773 | Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 7.7950\n",
            "Time lapsed = 1:31:14.800515\n",
            "Time left = 5:43:15.678128\n",
            "Saving Model!\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 22\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 22/100 | Train Loss 0.1869 | Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 7.8426\n",
            "Time lapsed = 1:35:35.902784\n",
            "Time left = 5:38:56.382598\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 23\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 23/100 | Train Loss 0.1751 | Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 7.5335\n",
            "Time lapsed = 1:39:57.189831\n",
            "Time left = 5:34:37.548565\n",
            "Saving Model!\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 24\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 24/100 | Train Loss 0.1630 | Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 7.8951\n",
            "Time lapsed = 1:44:18.524043\n",
            "Time left = 5:30:18.659470\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 25\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 25/100 | Train Loss 0.1620 | Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 7.5911\n",
            "Time lapsed = 1:48:39.793431\n",
            "Time left = 5:25:59.380293\n",
            "Saving Model!\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 26\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 26/100 | Train Loss 0.1539 | Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 7.5923\n",
            "Time lapsed = 1:53:01.048154\n",
            "Time left = 5:21:39.906284\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 27/100 | Train Loss 0.1511 | Learning Rate 0.0020\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 7.6685\n",
            "Time lapsed = 1:57:22.447096\n",
            "Time left = 5:17:20.690297\n",
            "Saving Model!\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 28\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 28/100 | Train Loss 0.1184 | Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 6.7020\n",
            "Time lapsed = 2:01:43.496271\n",
            "Time left = 5:13:00.418983\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 29\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 29/100 | Train Loss 0.1026 | Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 6.8162\n",
            "Time lapsed = 2:06:04.623528\n",
            "Time left = 5:08:40.285189\n",
            "Saving Model!\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 30\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 30/100 | Train Loss 0.0966 | Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 6.8199\n",
            "Time lapsed = 2:10:25.934736\n",
            "Time left = 5:04:20.514384\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 31\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 31/100 | Train Loss 0.0923 | Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 6.9349\n",
            "Time lapsed = 2:14:47.791290\n",
            "Time left = 5:00:01.858033\n",
            "Saving Model!\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 32\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 32/100 | Train Loss 0.0912 | Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 6.8341\n",
            "Time lapsed = 2:19:09.042544\n",
            "Time left = 4:55:41.715406\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 33\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 33/100 | Train Loss 0.0885 | Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 6.8780\n",
            "Time lapsed = 2:23:30.426080\n",
            "Time left = 4:51:21.774162\n",
            "Saving Model!\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 34/100 | Train Loss 0.0855 | Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 6.8538\n",
            "Time lapsed = 2:27:51.005792\n",
            "Time left = 4:47:00.187714\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 35\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 35/100 | Train Loss 0.0858 | Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 6.8594\n",
            "Time lapsed = 2:32:12.580876\n",
            "Time left = 4:42:40.507341\n",
            "Saving Model!\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 36\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 36/100 | Train Loss 0.0820 | Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 6.7917\n",
            "Time lapsed = 2:36:33.813272\n",
            "Time left = 4:38:20.112484\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 37\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 37/100 | Train Loss 0.0803 | Learning Rate 0.0010\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            ""
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Validation LD: 6.9245\n",
            "Time lapsed = 2:40:55.207877\n",
            "Time left = 4:33:59.948547\n",
            "Saving Model!\n",
            "Saving Checkpoint!\n",
            "\n",
            "Epoch- 38\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Train:  45%|     | 99/222 [01:40<02:06,  1.03s/it, loss=0.0779, lr=0.0010]"
          ]
        }
      ],
      "source": [
        "torch.cuda.empty_cache()\n",
        "asr.train()\n",
        "asr.save_model()\n",
        "\n",
        "if asr.log: wandb.finish()\n",
        "\n",
        "latest_model_name = asr.model_name"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I2ptgaeHadVN"
      },
      "source": [
        "# Testing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KMSwlCIDacCP"
      },
      "outputs": [],
      "source": [
        "# # def calculate_levenshtein(h, y, lh, ly, decoder):\n",
        "# #     # TODO: call the decoder's decode method and get beam_results and out_len (Read the docs about the decode method's outputs)\n",
        "# #     # Input to the decode method will be h and its lengths lh \n",
        "# #     # You need to pass lh for the 'seq_lens' parameter. This is not explicitly mentioned in the git repo of ctcdecode.\n",
        "\n",
        "# #     batch_size = 128\n",
        "# #     dist = 0\n",
        "# #     phoneme_map = dict(zip(PHONEMES, PHONEME_MAP))\n",
        "# #     beam_results, beam_scores, timesteps, out_lens = decoder.decode(h)\n",
        "\n",
        "# #     for i in range(batch_size): \n",
        "# #         h_sliced = beam_results[i][0][:out_lens[i][0]]\n",
        "# #         h_string = ''.join([phoneme_map[PHONEMES[idx]] for idx in h_sliced])\n",
        "\n",
        "# #         y_sliced = y[i][:ly[i]]\n",
        "# #         y_string = ''.join([phoneme_map[PHONEMES[idx]] for idx in y_sliced])\n",
        "        \n",
        "# #         dist += Levenshtein.distance(h_string, y_string)\n",
        "\n",
        "# #     dist/=batch_size\n",
        "# #     print(dist)\n",
        "\n",
        "# #     # return dist\n",
        "\n",
        "# config = {\n",
        "#     '': '',\n",
        "#     'batch_size': 128,\n",
        "#     'epochs': 1,\n",
        "#     'scheduler': None,              # CosineAnnealingLR, ReduceLRonPlateau\n",
        "#     'optimizer': 'Adam',            # SGD, Adam, AdamW\n",
        "#     'optim': {'lr': 0.002},\n",
        "#     'decoder': {'beam_width': 5, 'cutoff_top_n': 40, 'cutoff_prob': 1.0},\n",
        "#     'arch': {'input_size': 13, 'embedding_size': [64, 128], 'hidden_size': 256, 'num_layers': 4},\n",
        "#     'save': True,\n",
        "#     'log': True,\n",
        "#     'randomize': False,\n",
        "# }\n",
        "# torch.cuda.empty_cache()\n",
        "# decoder = CTCBeamDecoder(\n",
        "#         PHONEMES,\n",
        "#         alpha=0,\n",
        "#         beta=0,\n",
        "#         cutoff_top_n=40,\n",
        "#         cutoff_prob=1.0,\n",
        "#         beam_width=5,\n",
        "#         blank_id=0,\n",
        "#         log_probs_input=True\n",
        "# )\n",
        "# model = SpeechNet(config).cuda()\n",
        "# optimizer = optim.Adam(model.parameters(), lr=0.002)\n",
        "# criterion = nn.CTCLoss().cuda()\n",
        "\n",
        "# for i, data in enumerate(train_loader):\n",
        "#     torch.cuda.empty_cache()\n",
        "#     x, y, x_len, y_len = data\n",
        "#     print(\"Iteration \", i, \"-\"*50)\n",
        "#     print(\"Input = \", x.shape, x_len.shape)\n",
        "#     print(\"Target = \", y.shape, y_len.shape)\n",
        "\n",
        "#     model.train()\n",
        "#     optimizer.zero_grad()\n",
        "\n",
        "#     x = x.cuda()\n",
        "#     y = y.cuda()\n",
        "#     output, output_len = model(x.cuda(), x_len)\n",
        "#     # print(output[0], output_len[0])\n",
        "#     # print(y[0], y_len[0])\n",
        "#     print(\"Output = \", output.shape, output_len.shape)\n",
        "#     loss = criterion(torch.transpose(output, 0, 1), y, output_len, y_len)\n",
        "#     print(\"Training Loss =\", loss)\n",
        "\n",
        "#     # output = torch.transpose(output, 0, 1)\n",
        "#     # print(\"Output Transposed = \", output.shape)\n",
        "#     ld = calculate_levenshtein(decoder, output, y, output_len, y_len)\n",
        "#     print(ld)\n",
        "#     loss.backward()\n",
        "#     optimizer.step()\n",
        "\n",
        "#     # Write a test code do perform a single forward pass and also compute the Levenshtein distance\n",
        "#     # Make sure that you are able to get this right before going on to the actual training\n",
        "#     # You may encounter a lot of shape errors\n",
        "#     # Printing out the shapes will help in debugging\n",
        "#     # Keep in mind that the Loss which you will use requires the input to be in a different format and the decoder expects it in a different format\n",
        "#     # Make sure to read the corresponding docs about it\n",
        "# del model\n",
        "# # beam_results, beam_scores, timesteps, out_lens = decoder.decode(output)\n",
        "# # print(\"Decoder = \", beam_results.shape, beam_scores.shape, timesteps.shape, out_lens.shape)\n",
        "# # phoneme_map = dict(zip(PHONEMES, PHONEME_MAP))\n",
        "# # # First datapoint in batch\n",
        "# # test_beam = beam_results[0]\n",
        "# # test_len = out_lens[0]\n",
        "\n",
        "# # print(test_beam.shape)\n",
        "# # print(test_len.shape)\n",
        "\n",
        "# # # First Beam\n",
        "# # h_sliced = test_beam[0][:test_len[0]]\n",
        "# # print(\"Top beam = \", h_sliced.shape)\n",
        "# # h_string = ''.join([phoneme_map[PHONEMES[idx]] for idx in h_sliced])\n",
        "# # print(\"Top beam mapping = \", h_string)\n",
        "# # print(\"Top beam length = \", len(h_string))\n",
        "\n",
        "# # print(\"\\n\")\n",
        "\n",
        "# # # Target Output\n",
        "# # print(y.shape)\n",
        "# # print(y_len.shape)\n",
        "# # y_sliced = y[0][:y_len[0]]\n",
        "# # print(\"Target Seq = \", y_sliced.shape)\n",
        "# # y_string = ''.join([phoneme_map[PHONEMES[idx]] for idx in y_sliced])\n",
        "# # print(\"Target Seq mapping = \", y_string)\n",
        "# # print(\"Target Seq length = \", len(y_string))\n",
        "\n",
        "# # # Score\n",
        "# # print(\"\\n\\nLevenshtein Distance = \", Levenshtein.distance(h_string, y_string))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JcvuIBpl7jlq",
        "outputId": "7229d79f-c5c7-48bc-c589-53f41eb70c4a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "tensor(1.0000, device='cuda:0', grad_fn=<SumBackward0>)\n"
          ]
        }
      ],
      "source": [
        "# print(output[0][0].sum())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ROrqXnNqzJSc"
      },
      "source": [
        "# Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "brfFR9m2v-8u"
      },
      "outputs": [],
      "source": [
        "class SpeechInference():\n",
        "    def __init__(self):\n",
        "        self.phonemes = PHONEMES\n",
        "        self.phoneme_map = dict(zip(PHONEMES, PHONEME_MAP))\n",
        "\n",
        "        self.drive_dir = r'/content/cmudrive/IDL'\n",
        "        # Dataset and dataloader\n",
        "        self.test_data = LibriSamples(partition='test')\n",
        "        self.test_loader = DataLoader(\n",
        "            self.test_data, \n",
        "            batch_size=256, \n",
        "            shuffle=False, \n",
        "            drop_last=False, \n",
        "            collate_fn = self.test_data.collate_fn\n",
        "            )\n",
        "        \n",
        "        self.decoder = CTCBeamDecoder(\n",
        "                PHONEME_MAP,\n",
        "                blank_id=0,\n",
        "                log_probs_input=True,\n",
        "                beam_width= 50, \n",
        "                cutoff_top_n= 40,\n",
        "                cutoff_prob= 1.0\n",
        "        )\n",
        "        \n",
        "    def get_predictions(self, model):\n",
        "        model.eval()\n",
        "        predictions = []\n",
        "        batch_bar = tqdm(total=len(self.test_loader), position=0, leave=False, desc='Test')\n",
        "        with torch.no_grad():\n",
        "            for i, data in tqdm(enumerate(self.test_loader)):\n",
        "                x, x_len = data\n",
        "                x = x.cuda()\n",
        "\n",
        "                with torch.no_grad():    \n",
        "                    output, output_len = model(x, x_len)\n",
        "\n",
        "                beam_results, beam_scores, timesteps, out_lens = self.decoder.decode(output, seq_lens=output_len)\n",
        "                for b in range(output.shape[0]):\n",
        "                    predictions.append(convert_to_string(beam_results[b][0], out_lens[b][0], self.phoneme_map, self.phonemes))\n",
        "                \n",
        "                batch_bar.update()\n",
        "\n",
        "            batch_bar.close()\n",
        "\n",
        "        return predictions\n",
        "\n",
        "    def load_model(self, model_name, model_type): \n",
        "        meta_path = os.path.join(self.drive_dir,  model_type, model_name, 'model_config.yaml')\n",
        "        with open(meta_path, 'r') as meta:\n",
        "            args = yaml.safe_load(meta)\n",
        "\n",
        "        model_path = os.path.join(self.drive_dir, model_type, model_name, 'model.pth')\n",
        "        model = SpeechNet(args).cuda()\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "        return model, args\n",
        "\n",
        "    def simple_inference(self, model_name, model_type):\n",
        "        print(\"Running inference...\")\n",
        "        self.timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "        model, args = self.load_model(model_name, model_type)\n",
        "        preds = self.get_predictions(model)\n",
        "        \n",
        "        return preds\n",
        "\n",
        "    def ensemble_inference(self, model_names, model_type):\n",
        "        print(\"Running ensembled inference...\")\n",
        "        self.timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "\n",
        "        prelim_labels = []\n",
        "        for name in model_names:\n",
        "            print(\"\\n\\n\\tModel : \", name)\n",
        "            model, args = self.load_model(name, model_type)\n",
        "            prelim_labels.append(self.__get_labels(model, args))\n",
        "\n",
        "        accs = [86.146, 85.79, 84.95]\n",
        "        w = accs / np.sum(accs)\n",
        "\n",
        "        print(\"Combining predictions...\")\n",
        "        labels_df = pd.DataFrame(prelim_labels)\n",
        "        labels_df = labels_df.transpose()\n",
        "        ensembled_labels = labels_df.mode(axis=1, dropna=False).iloc[:, 0].tolist()\n",
        "        # ensembled_labels = np.where((df.iloc[:,1] == df.iloc[:, 2]), df.iloc[:, 1], df.iloc[:, 0]).tolist()\n",
        "\n",
        "        return labels_df, ensembled_labels\n",
        "\n",
        "    def generate_submission(self, save_path, preds): \n",
        "        print(\"Generating Submission CSV...\")\n",
        "        sub_dir = os.path.join(self.drive_dir, save_path + self.timestamp)\n",
        "        try:\n",
        "            os.mkdir(sub_dir)\n",
        "        except:\n",
        "            print(\"Couldn't create folder for submission.csv\")\n",
        "            \n",
        "        sub_path = os.path.join(sub_dir, 'submission.csv')\n",
        "\n",
        "        with open(sub_path, 'w') as f:\n",
        "            csvwrite = csv.writer(f)\n",
        "            csvwrite.writerow(['id', 'predictions'])\n",
        "            for i in range(len(preds)):\n",
        "                csvwrite.writerow([i, preds[i]])\n",
        "\n",
        "        print(f\"File saved at : {sub_path}\")\n",
        "        return sub_path"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nswfp1XMwz3a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 675
        },
        "outputId": "68055284-8a28-4310-b6ea-39b315b47c66"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Data: 100%|| 2620/2620 [00:00<00:00, 2716.64it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running inference...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Test:   0%|          | 0/11 [00:00<?, ?it/s]\n",
            "Test:   9%|         | 1/11 [00:21<03:34, 21.46s/it]\n",
            "Test:  18%|        | 2/11 [00:47<03:38, 24.29s/it]\n",
            "Test:  27%|       | 3/11 [01:21<03:50, 28.81s/it]\n",
            "Test:  36%|      | 4/11 [01:51<03:24, 29.22s/it]\n",
            "Test:  45%|     | 5/11 [02:23<03:01, 30.21s/it]\n",
            "Test:  55%|    | 6/11 [02:56<02:35, 31.10s/it]\n",
            "Test:  64%|   | 7/11 [03:22<01:58, 29.56s/it]\n",
            "Test:  73%|  | 8/11 [03:50<01:26, 29.00s/it]\n",
            "Test:  82%| | 9/11 [04:19<00:57, 28.81s/it]\n",
            "Test:  91%| | 10/11 [04:55<00:30, 30.99s/it]\n",
            "Test: 100%|| 11/11 [05:02<00:00, 23.81s/it]\n",
            "11it [05:02, 27.51s/it]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Generating Submission CSV...\n",
            "File saved at : /content/cmudrive/IDL/hw3-submission/2022-03-30_18-36-37/submission.csv\n",
            "Preview of submission.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   id                                        predictions\n",
              "0   0  .HIbIgAnhkhnf?UsdkhmplEnthgenstDhWizrd.HUAdvAn...\n",
              "1   1             ..kivnatsO.rnhsthmyndthDIzmhmrIizcyld.\n",
              "2   2                        .hgOldhnfoRchninhHApI.lyf..\n",
              "3   3       .HIWhzlykhntmyfaDrAndhWE.And?etWhznatmyfaDr.\n",
              "4   4            .olsODeRWhzhstRipliNpEj.HUtrndittUhmIt.\n",
              "5   5     .DisWhzsOsWIthlEdIsr.AndinshmbAnrydUTiNkSIdyd.\n",
              "6   6               .bhtDenDhpikcrWhzgonezkWiklIAzhkEm..\n",
              "7   7                       ..sistrnOdU?UHIhDIzmaRvhlz..\n",
              "8   8          .tEk?oRplEshnlethsIWiDDhkRisphlkhnSOth?U.\n",
              "9   9                 .lykiznat?hNmAstr.DO.yAmhnOldmAn.."
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fd6433d5-f3a5-4964-8646-c972f81d9140\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>predictions</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>.HIbIgAnhkhnf?UsdkhmplEnthgenstDhWizrd.HUAdvAn...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>..kivnatsO.rnhsthmyndthDIzmhmrIizcyld.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>.hgOldhnfoRchninhHApI.lyf..</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>.HIWhzlykhntmyfaDrAndhWE.And?etWhznatmyfaDr.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>.olsODeRWhzhstRipliNpEj.HUtrndittUhmIt.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>.DisWhzsOsWIthlEdIsr.AndinshmbAnrydUTiNkSIdyd.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>.bhtDenDhpikcrWhzgonezkWiklIAzhkEm..</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>..sistrnOdU?UHIhDIzmaRvhlz..</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>.tEk?oRplEshnlethsIWiDDhkRisphlkhnSOth?U.</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>.lykiznat?hNmAstr.DO.yAmhnOldmAn..</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fd6433d5-f3a5-4964-8646-c972f81d9140')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fd6433d5-f3a5-4964-8646-c972f81d9140 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fd6433d5-f3a5-4964-8646-c972f81d9140');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ],
      "source": [
        "model_name = r'LSTM-4layer-[64, 128]-256-4-0.2_b128_e100_sRLRP_oAdamP_rLSTM_lr0.002'\n",
        "# model_name = latest_model_name\n",
        "# models = [\n",
        "#           r'full_Finale_b16384_e25_c16_bnafter_wNone_oadamp_sNone_d0.25_lr0.001-ver81',\n",
        "#           r'full_Ensemble1_b16384_e20_c16_bnafter_wNone_oadamp_sNone_d0.25_lr0.001-ver48',\n",
        "#           r'full_Ensemble2_b16384_e15_c32_bnafter_wNone_oadamp_sNone_d0.25_lr0.001-ver81'\n",
        "#           ]\n",
        "\n",
        "model_type = r'hw3-ablations'\n",
        "sub_path = r'hw3-submission/'\n",
        "inference = SpeechInference()\n",
        "\n",
        "predictions = inference.simple_inference(model_name, model_type)\n",
        "submission_path = inference.generate_submission(sub_path, predictions)\n",
        "\n",
        "# Simple and Ensemble Inference\n",
        "# labels = inference.simple_inference(model_name, model_type)\n",
        "# labels_df, labels = inference.ensemble_inference(models, model_type)\n",
        "\n",
        "print(f\"Preview of submission.csv\")\n",
        "df = pd.read_csv(submission_path)\n",
        "df.head(10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "03-w9it1pXIi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b42f9dc3-08db-473d-ce26-2d9fae8e9279"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cmudrive/IDL/hw3-submission/2022-03-30_18-36-37/submission.csv\n",
            "100% 215k/215k [00:00<00:00, 904kB/s]\n",
            "Successfully submitted to Automatic Speech Recognition (ASR)"
          ]
        }
      ],
      "source": [
        "print(submission_path)\n",
        "! kaggle competitions submit -c 11-785-s22-hw3p2 -f $submission_path -m \"Midpoint submission\""
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "f_fwJWcpqJDR",
        "z4vZbDmJvMp1",
        "vUCKqm1ST1sU",
        "Ly4mjUUUuJhy",
        "yA-6ZrNI_rSi",
        "bC78fom2_tfD",
        "7yLRX4iwPP90",
        "72yaABA_w8kt",
        "I2ptgaeHadVN",
        "ROrqXnNqzJSc"
      ],
      "name": "Copy of HW3P2.ipynb",
      "provenance": [],
      "machine_shape": "hm",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
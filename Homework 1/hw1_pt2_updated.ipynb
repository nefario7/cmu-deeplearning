{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nefario7/cmu-deeplearning/blob/working-hw1/hw1_pt2_updated.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pEEirl65cINF"
      },
      "source": [
        "### Mount drive and download dataset"
      ],
      "id": "pEEirl65cINF"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NeSRw6SuWkx2"
      },
      "outputs": [],
      "source": [
        "from IPython.display import clear_output \n",
        "! apt-get install -y -qq software-properties-common python-software-properties module-init-tools\n",
        "! add-apt-repository -y ppa:alessandro-strada/ppa 2>&1 > /dev/null\n",
        "! apt-get update -qq 2>&1 > /dev/null\n",
        "! apt-get -y install -qq google-drive-ocamlfuse fuse\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "from oauth2client.client import GoogleCredentials\n",
        "creds = GoogleCredentials.get_application_default()\n",
        "import getpass\n",
        "\n",
        "! google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret} < /dev/null 2>&1 | grep URL\n",
        "vcode = getpass.getpass()\n",
        "! echo {vcode} | google-drive-ocamlfuse -headless -id={creds.client_id} -secret={creds.client_secret}\n",
        "% cd /content\n",
        "! mkdir cmudrive\n",
        "% cd ..\n",
        "! google-drive-ocamlfuse /content/cmudrive\n",
        "! pip install kaggle wandb torch-summary\n",
        "! mkdir ~/.kaggle\n",
        "! cp /content/cmudrive/IDL/kaggle.json ~/.kaggle/\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "! wandb login\n",
        "\n",
        "! pip install --upgrade --force-reinstall --no-deps kaggleÂ \n",
        "! kaggle config set -n path -v /content\n",
        "! kaggle competitions download -c 11-785-s22-hw1p2\n",
        "! unzip -q /content/competitions/11-785-s22-hw1p2/11-785-s22-hw1p2.zip -d /content/hw1-data\n",
        "\n",
        "clear_output()"
      ],
      "id": "NeSRw6SuWkx2"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27RRsooJcNMM"
      },
      "source": [
        "### Dependencies"
      ],
      "id": "27RRsooJcNMM"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MIby3J0IWvkY"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import csv\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from sklearn.metrics import accuracy_score"
      ],
      "id": "MIby3J0IWvkY"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eYe24iHXXw5e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c54d0ca2-378f-41be-a578-f7e22cab9a21"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting adamp\n",
            "  Downloading adamp-0.3.0.tar.gz (5.1 kB)\n",
            "Building wheels for collected packages: adamp\n",
            "  Building wheel for adamp (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for adamp: filename=adamp-0.3.0-py3-none-any.whl size=5998 sha256=9ef9016070eb31b67cc9d3fde03b6f030419ac578727cd9a96adae45a0c1a958\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/95/21/ced2d2cb9944e3a72e58fece7958973eed3fd8d0aeb6e2e450\n",
            "Successfully built adamp\n",
            "Installing collected packages: adamp\n",
            "Successfully installed adamp-0.3.0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.profiler.emit_nvtx at 0x7f52e08ad590>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ],
      "source": [
        "import wandb\n",
        "import yaml\n",
        "import time\n",
        "import csv\n",
        "import pandas as pd\n",
        "from torchsummary import summary\n",
        "from torch.cuda.amp import GradScaler, autocast\n",
        "from torch.optim.lr_scheduler import ExponentialLR, ReduceLROnPlateau\n",
        "# from pytorch_lightning.callbacks.early_stopping import EarlyStopping\n",
        "! pip3 install adamp\n",
        "from adamp import AdamP\n",
        "\n",
        "torch.autograd.set_detect_anomaly(False)\n",
        "torch.autograd.profiler.profile(False)\n",
        "torch.autograd.profiler.emit_nvtx(False)"
      ],
      "id": "eYe24iHXXw5e"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9vFFGI9FcPd8"
      },
      "source": [
        "### Network Architecture and Dataloaders"
      ],
      "id": "9vFFGI9FcPd8"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RREp-ifWY6Yy"
      },
      "outputs": [],
      "source": [
        "def model_saving(path, args, save_metadata=True, exp=\"Experiment\", ensemble=False):\n",
        "    save_name = ''\n",
        "    if not args['CSV_PATH']:\n",
        "        save_name += \"full_\"\n",
        "\n",
        "    for parameter, val in args.items():\n",
        "        abbr = parameter[0] if len(parameter) > 2 else parameter\n",
        "        if parameter == 'lr' :\n",
        "            data = abbr + str(val)\n",
        "            save_name += data\n",
        "            break\n",
        "        else:\n",
        "            data = abbr + str(val) + '_'\n",
        "            save_name += data\n",
        "\n",
        "    if ensemble:\n",
        "        save_name = save_name + \"-ver\" + str(np.random.randint(10, 100))\n",
        "\n",
        "    print(\"\\nModel will be saved as : \", save_name)\n",
        "    save_path = os.path.join(path, save_name)\n",
        "    try:\n",
        "        os.mkdir(save_path)\n",
        "    except FileExistsError:\n",
        "            d = input(\"Model name already exists. Delete existing model? (y/n)\")\n",
        "            if d == 'y':\n",
        "                import shutil\n",
        "                shutil.rmtree(save_path)\n",
        "                os.mkdir(save_path)\n",
        "            else:\n",
        "                return None\n",
        "\n",
        "    with open(os.path.join(save_path, 'model_parameters.yaml'), 'w') as metadata:\n",
        "        yaml.dump({'Experiment': exp}, metadata, indent=8, default_flow_style=False)\n",
        "        yaml.dump(args, metadata, indent=4, default_flow_style=False)\n",
        "\n",
        "    return save_path\n",
        "\n",
        "def save_model(args, model, model_path, save_best=False):\n",
        "    if save_best:\n",
        "        torch.save(model.state_dict(), os.path.join(model_path, \"best_model.pth\"))\n",
        "    else:\n",
        "        torch.save(model.state_dict(), os.path.join(model_path, \"model.pth\"))\n",
        "        # torch.save(model, os.path.join(model_path, \"model.pth\"))\n",
        "    print(\"Model saved at : \", model_path)\n",
        "\n",
        "def initialize_weights(m):\n",
        "  if isinstance(m, nn.BatchNorm2d):\n",
        "      nn.init.constant_(m.weight.data, 1)\n",
        "      nn.init.constant_(m.bias.data, 0)\n",
        "  elif isinstance(m, nn.Linear):\n",
        "      nn.init.kaiming_uniform_(m.weight.data)\n",
        "      nn.init.constant_(m.bias.data, 0)\n",
        "    "
      ],
      "id": "RREp-ifWY6Yy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qcny8yCsWxmq"
      },
      "outputs": [],
      "source": [
        "class Network(torch.nn.Module):\n",
        "    def __init__(self, arch, context=0, drop=0.1):\n",
        "        super(Network, self).__init__()\n",
        "        c = (1 + 2 * context)\n",
        "        INPUT_SIZE = c * 13\n",
        "        NUM_CLASSES = 40\n",
        "\n",
        "        layers = []\n",
        "        sizes = [INPUT_SIZE] + arch + [NUM_CLASSES]\n",
        "        \n",
        "        print(\"Network Architecture\")\n",
        "        print(f\"No. of hidden layers  = {len(sizes) - 2}, Max. Width = {max(sizes)}\")\n",
        "        for i in range(len(sizes) - 1):\n",
        "            layers.append(nn.Linear(sizes[i], sizes[i+1]))\n",
        "            if sizes[i+1] != NUM_CLASSES:\n",
        "                layers.append(nn.ReLU())\n",
        "                layers.append(nn.BatchNorm1d(num_features = sizes[i+1]))\n",
        "                layers.append(nn.Dropout(drop))\n",
        "        \n",
        "        self.classifier = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, A0):\n",
        "        x = self.classifier(A0)\n",
        "        return x"
      ],
      "id": "Qcny8yCsWxmq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Jr9VJwbGWxrY"
      },
      "outputs": [],
      "source": [
        "class LibriSamples(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_path, sample=20000, shuffle=True, partition=\"dev-clean\", csvpath=None):\n",
        "        # sample represent how many npy files will be preloaded for one __getitem__ call\n",
        "        self.sample = sample \n",
        "        \n",
        "        self.X_dir = data_path + \"/\" + partition + \"/mfcc/\"\n",
        "        self.Y_dir = data_path + \"/\" + partition +\"/transcript/\"\n",
        "        \n",
        "        self.X_names = os.listdir(self.X_dir)\n",
        "        self.Y_names = os.listdir(self.Y_dir)\n",
        "\n",
        "        # using a small part of the dataset to debug\n",
        "        if csvpath:\n",
        "            subset = self.parse_csv(csvpath)\n",
        "            self.X_names = [i for i in self.X_names if i in subset]\n",
        "            self.Y_names = [i for i in self.Y_names if i in subset]\n",
        "        \n",
        "        if shuffle == True:\n",
        "            XY_names = list(zip(self.X_names, self.Y_names))\n",
        "            random.shuffle(XY_names)\n",
        "            self.X_names, self.Y_names = zip(*XY_names)\n",
        "        \n",
        "        assert(len(self.X_names) == len(self.Y_names))\n",
        "        self.length = len(self.X_names)\n",
        "        \n",
        "        self.PHONEMES = [\n",
        "            'SIL',   'AA',    'AE',    'AH',    'AO',    'AW',    'AY',  \n",
        "            'B',     'CH',    'D',     'DH',    'EH',    'ER',    'EY',\n",
        "            'F',     'G',     'HH',    'IH',    'IY',    'JH',    'K',\n",
        "            'L',     'M',     'N',     'NG',    'OW',    'OY',    'P',\n",
        "            'R',     'S',     'SH',    'T',     'TH',    'UH',    'UW',\n",
        "            'V',     'W',     'Y',     'Z',     'ZH',    '<sos>', '<eos>']\n",
        "      \n",
        "    @staticmethod\n",
        "    def parse_csv(filepath):\n",
        "        subset = []\n",
        "        with open(filepath) as f:\n",
        "            f_csv = csv.reader(f)\n",
        "            for row in f_csv:\n",
        "                subset.append(row[1])\n",
        "        return subset[1:]\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(self.length / self.sample))\n",
        "        \n",
        "    def __getitem__(self, i):\n",
        "        sample_range = range(i*self.sample, min((i+1)*self.sample, self.length))\n",
        "        \n",
        "        X, Y = [], []\n",
        "        for j in sample_range:\n",
        "            X_path = self.X_dir + self.X_names[j]\n",
        "            Y_path = self.Y_dir + self.Y_names[j]\n",
        "            \n",
        "            label = [self.PHONEMES.index(yy) for yy in np.load(Y_path)][1:-1]\n",
        "\n",
        "            X_data = np.load(X_path)\n",
        "            X_data = (X_data - X_data.mean(axis=0))/X_data.std(axis=0)\n",
        "            X.append(X_data)\n",
        "            Y.append(np.array(label))\n",
        "            \n",
        "        X, Y = np.concatenate(X), np.concatenate(Y)\n",
        "        return X, Y\n",
        "    \n",
        "class LibriItems(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, Y, context = 0):\n",
        "        assert(X.shape[0] == Y.shape[0])\n",
        "        \n",
        "        self.length  = X.shape[0]\n",
        "        self.context = context\n",
        "\n",
        "        if context == 0:\n",
        "            self.X, self.Y = X, Y\n",
        "        else:\n",
        "            X = np.pad(X, ((context,context), (0,0)), 'constant', constant_values=(0,0))\n",
        "            self.X, self.Y = X, Y\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "        \n",
        "    def __getitem__(self, i):\n",
        "        if self.context == 0:\n",
        "            xx = self.X[i].flatten()\n",
        "            yy = self.Y[i]\n",
        "        else:\n",
        "            xx = self.X[i:(i + 2*self.context + 1)].flatten()\n",
        "            yy = self.Y[i]\n",
        "        return xx, yy"
      ],
      "id": "Jr9VJwbGWxrY"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uc3cpN3gcSyy"
      },
      "source": [
        "### Training and Testing"
      ],
      "id": "uc3cpN3gcSyy"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2cbb1d57"
      },
      "outputs": [],
      "source": [
        "def train(args, model, device, train_samples, optimizer, criterion, epoch):\n",
        "    model.train()\n",
        "    scaler = GradScaler()\n",
        "\n",
        "    if args[\"log\"]:\n",
        "        wandb.watch(model, criterion, log=\"all\", log_freq=10)\n",
        "    for i in range(len(train_samples)):\n",
        "        X, Y = train_samples[i]\n",
        "        train_items = LibriItems(X, Y, context=args['context'])\n",
        "        train_loader = torch.utils.data.DataLoader(train_items, batch_size=args['batch_size'], num_workers=2, pin_memory=True, shuffle=True)\n",
        "\n",
        "        for batch_idx, (data, target) in enumerate(train_loader):\n",
        "            data = data.float().to(device)\n",
        "            target = target.long().to(device)\n",
        "\n",
        "            optimizer.zero_grad(set_to_none=True)\n",
        "            with autocast():\n",
        "                output = model(data)\n",
        "                loss = criterion(output, target)\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "            scaler.step(optimizer)\n",
        "            scaler.update()\n",
        "\n",
        "            if batch_idx % args['log_interval'] == 0:\n",
        "                if args['log']:\n",
        "                    wandb.log({\"Training Loss\": loss.item()})\n",
        "                    \n",
        "                print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
        "                    epoch, batch_idx * len(data), len(train_loader.dataset),\n",
        "                    100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "def test(args, model, device, criterion, dev_samples):\n",
        "    model.eval()\n",
        "    true_y_list = []\n",
        "    pred_y_list = []\n",
        "    with torch.no_grad():\n",
        "        for i in range(len(dev_samples)):\n",
        "            X, Y = dev_samples[i]\n",
        "\n",
        "            test_items = LibriItems(X, Y, context=args['context'])\n",
        "            test_loader = torch.utils.data.DataLoader(test_items, batch_size=args['batch_size'], shuffle=False)\n",
        "\n",
        "            for data, true_y in test_loader:\n",
        "                data = data.float().to(device)\n",
        "                true_y = true_y.long().to(device)                \n",
        "                \n",
        "                output = model(data)\n",
        "                val_loss = criterion(output, true_y)\n",
        "                if args['log']:\n",
        "                    wandb.log({\"Validation Loss\": val_loss.item()})\n",
        "                pred_y = torch.argmax(output, axis=1)\n",
        "\n",
        "                pred_y_list.extend(pred_y.tolist())\n",
        "                true_y_list.extend(true_y.tolist())\n",
        "\n",
        "    train_accuracy =  accuracy_score(true_y_list, pred_y_list)\n",
        "    return train_accuracy, val_loss"
      ],
      "id": "2cbb1d57"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Qp8TiVzCGw3M"
      },
      "outputs": [],
      "source": [
        "def main(args):\n",
        "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "    print(\"Using \", device)\n",
        "    \n",
        "    # Model\n",
        "    model = Network(args[\"arch\"], args['context'], args['drop']).to(device)\n",
        "    summary(model)\n",
        "    model_path = model_saving(\n",
        "            path=r'/content/cmudrive/IDL/hw1-models-sub', \n",
        "            args=args, \n",
        "            save_metadata=True, \n",
        "            exp=\"Cylinder\",\n",
        "            ensemble=args[\"ensemble\"]\n",
        "            )\n",
        "\n",
        "    # Weight Initialization\n",
        "    if args[\"weight\"] is not None:\n",
        "        print(\"\\nInitializing Weights\")\n",
        "        model.apply(initialize_weights)\n",
        "\n",
        "    # Optimizer\n",
        "    if args[\"optimizer\"] == 'adam':\n",
        "        optimizer = optim.Adam(model.parameters(), lr=args['lr'], weight_decay=1e-5)\n",
        "    elif args[\"optimizer\"] == 'sgdn':\n",
        "        optimizer = optim.SGD(model.parameters(), lr=args['lr'], momentum=0.9, nesterov=True)\n",
        "    elif args[\"optimizer\"] == 'adamp':\n",
        "        optimizer = AdamP(model.parameters(), lr=args['lr'], betas=(0.9, 0.999), weight_decay=1e-2)\n",
        "\n",
        "    # Scheduler\n",
        "    if args[\"scheduler\"] == 'rlrop':\n",
        "        scheduler = ReduceLROnPlateau(optimizer, 'min')\n",
        "    if args[\"scheduler\"] == 'exp':\n",
        "        scheduler = ExponentialLR(optimizer, gamma=0.9)\n",
        "\n",
        "    # Loss\n",
        "    criterion = torch.nn.CrossEntropyLoss()\n",
        "\n",
        "    # Dataloaders\n",
        "    train_samples = LibriSamples(data_path = args['LIBRI_PATH'], shuffle=True, partition=\"train-clean-100\", csvpath=args['CSV_PATH'])\n",
        "    dev_samples = LibriSamples(data_path = args['LIBRI_PATH'], shuffle=True, partition=\"dev-clean\")\n",
        "\n",
        "    if args['log']:\n",
        "        print(\"Initializing W&B\")\n",
        "        wandb.init(project=\"hw1-submission\", entity=\"nefario7\", config=args)\n",
        "\n",
        "    max_acc = 0\n",
        "    print(\"\\n------------------------------Training-----------------------------\")\n",
        "    for epoch in range(1, args['epoch'] + 1):\n",
        "        start = time.time()\n",
        "        train(args, model, device, train_samples, optimizer, criterion, epoch)\n",
        "        test_acc, val_loss = test(args, model, device, criterion, dev_samples)\n",
        "\n",
        "        if args[\"scheduler\"] is not None:\n",
        "            scheduler.step(val_loss)\n",
        "            if args['log']:\n",
        "                print(f\"Learning Rate: {scheduler.get_last_lr()}\")\n",
        "                wandb.log({\"Learning Rate\": scheduler.get_last_lr()})\n",
        "\n",
        "        if args['log']:\n",
        "            wandb.log({\"Accuracy\": test_acc * 100})\n",
        "        print(f'Validation Accuracy = {test_acc * 100}%')\n",
        "\n",
        "        end = time.time()\n",
        "        print(f'Time taken = {end - start} secs\\n')\n",
        "\n",
        "        if args['save'] and test_acc > max_acc:\n",
        "            print(\"\\nSaving best model!\")\n",
        "            max_acc = test_acc\n",
        "            save_model(args, model, model_path, save_best=True)\n",
        "\n",
        "\n",
        "    print(\"\\n-------------------------Training Complete!------------------------\")\n",
        "\n",
        "    if args['save']:\n",
        "        save_model(args, model, model_path)\n",
        "\n",
        "    if args['log']:\n",
        "        wandb.finish()"
      ],
      "id": "Qp8TiVzCGw3M"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3I_Ds0n8LBTd"
      },
      "source": [
        "### Run"
      ],
      "id": "3I_Ds0n8LBTd"
    },
    {
      "cell_type": "code",
      "source": [
        "# Context 16 - 81.95\n",
        "# Context 32 - 81.872\n",
        "# LR 0.01 - 75.47\n",
        "# AdamP - 82.2\n",
        "\n",
        "# Finale Arch = [4096/2048, 2048, 2048, 2048, 1024, 512, 256]\n",
        "# Ensemble Arch 1 = [512, 1024, 2048, 4096, 2048, 1024, 512, 256]\n",
        "\n",
        "args = {\n",
        "    '': 'Ensemble2',\n",
        "    'batch_size': 16384,\n",
        "    'epoch': 15,\n",
        "    'context': 32,\n",
        "    'bn': 'after',\n",
        "    'weight': None, \n",
        "    'optimizer': 'adamp',\n",
        "    'scheduler': None,\n",
        "    'drop': 0.25,\n",
        "    'lr': 0.001,\n",
        "    'arch': [1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024],\n",
        "    'LIBRI_PATH': '/content/hw1-data/hw1p2_student_data',\n",
        "    'CSV_PATH': None,\n",
        "    'log_interval': 200,\n",
        "    'save' : True,\n",
        "    'log' : True,\n",
        "    'ensemble': True\n",
        "}\n",
        "\n",
        "torch.cuda.empty_cache()\n",
        "main(args)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "132bee68595c4ff1a8af4e8b2ff72f2e",
            "ad3e230a109a41a3b70014c5e822b22a",
            "3c4ed1d3e9a0417592d804cf83bcd0f7",
            "fd9d47d8f6fe4cf4afbc9a8074c005dc",
            "9f4290771ab7487491665360bb4c55be",
            "6112d23b1ebd4e28a7af8493edf31650",
            "5d2d8c51ae174ec0ada0137c802073e4",
            "3104862bb0ee41478b5d374455603630"
          ]
        },
        "id": "TW3M6zsLNoUc",
        "outputId": "a60fd844-c84c-4f98-d5d5-9f9f3017e97b"
      },
      "id": "TW3M6zsLNoUc",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using  cuda\n",
            "Network Architecture\n",
            "No. of hidden layers  = 8, Max. Width = 1024\n",
            "=================================================================\n",
            "Layer (type:depth-idx)                   Param #\n",
            "=================================================================\n",
            "ââSequential: 1-1                        --\n",
            "|    ââLinear: 2-1                       866,304\n",
            "|    ââReLU: 2-2                         --\n",
            "|    ââBatchNorm1d: 2-3                  2,048\n",
            "|    ââDropout: 2-4                      --\n",
            "|    ââLinear: 2-5                       1,049,600\n",
            "|    ââReLU: 2-6                         --\n",
            "|    ââBatchNorm1d: 2-7                  2,048\n",
            "|    ââDropout: 2-8                      --\n",
            "|    ââLinear: 2-9                       1,049,600\n",
            "|    ââReLU: 2-10                        --\n",
            "|    ââBatchNorm1d: 2-11                 2,048\n",
            "|    ââDropout: 2-12                     --\n",
            "|    ââLinear: 2-13                      1,049,600\n",
            "|    ââReLU: 2-14                        --\n",
            "|    ââBatchNorm1d: 2-15                 2,048\n",
            "|    ââDropout: 2-16                     --\n",
            "|    ââLinear: 2-17                      1,049,600\n",
            "|    ââReLU: 2-18                        --\n",
            "|    ââBatchNorm1d: 2-19                 2,048\n",
            "|    ââDropout: 2-20                     --\n",
            "|    ââLinear: 2-21                      1,049,600\n",
            "|    ââReLU: 2-22                        --\n",
            "|    ââBatchNorm1d: 2-23                 2,048\n",
            "|    ââDropout: 2-24                     --\n",
            "|    ââLinear: 2-25                      1,049,600\n",
            "|    ââReLU: 2-26                        --\n",
            "|    ââBatchNorm1d: 2-27                 2,048\n",
            "|    ââDropout: 2-28                     --\n",
            "|    ââLinear: 2-29                      1,049,600\n",
            "|    ââReLU: 2-30                        --\n",
            "|    ââBatchNorm1d: 2-31                 2,048\n",
            "|    ââDropout: 2-32                     --\n",
            "|    ââLinear: 2-33                      41,000\n",
            "=================================================================\n",
            "Total params: 8,270,888\n",
            "Trainable params: 8,270,888\n",
            "Non-trainable params: 0\n",
            "=================================================================\n",
            "\n",
            "Model will be saved as :  full_Ensemble2_b16384_e15_c32_bnafter_wNone_oadamp_sNone_d0.25_lr0.001-ver81\n",
            "Initializing W&B\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mnefario7\u001b[0m (use `wandb login --relogin` to force relogin)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "                    Syncing run <strong><a href=\"https://wandb.ai/nefario7/hw1-submission/runs/3gezztp5\" target=\"_blank\">fluent-snowball-13</a></strong> to <a href=\"https://wandb.ai/nefario7/hw1-submission\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://docs.wandb.com/integrations/jupyter.html\" target=\"_blank\">docs</a>).<br/>\n",
              "\n",
              "                "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------------------------Training-----------------------------\n",
            "Train Epoch: 1 [0/25351378 (0%)]\tLoss: 3.905677\n",
            "Train Epoch: 1 [3276800/25351378 (13%)]\tLoss: 1.048918\n",
            "Train Epoch: 1 [6553600/25351378 (26%)]\tLoss: 0.929813\n",
            "Train Epoch: 1 [9830400/25351378 (39%)]\tLoss: 0.872737\n",
            "Train Epoch: 1 [13107200/25351378 (52%)]\tLoss: 0.833595\n",
            "Train Epoch: 1 [16384000/25351378 (65%)]\tLoss: 0.805122\n",
            "Train Epoch: 1 [19660800/25351378 (78%)]\tLoss: 0.784250\n",
            "Train Epoch: 1 [22937600/25351378 (90%)]\tLoss: 0.767015\n",
            "Train Epoch: 1 [0/10839756 (0%)]\tLoss: 0.769532\n",
            "Train Epoch: 1 [3276800/10839756 (30%)]\tLoss: 0.747903\n",
            "Train Epoch: 1 [6553600/10839756 (60%)]\tLoss: 0.705713\n",
            "Train Epoch: 1 [9830400/10839756 (91%)]\tLoss: 0.717238\n",
            "Validation Accuracy = 79.28775078761453%\n",
            "Time taken = 434.29023122787476 secs\n",
            "\n",
            "\n",
            "Saving best model!\n",
            "Model saved at :  /content/cmudrive/IDL/hw1-models-sub/full_Ensemble2_b16384_e15_c32_bnafter_wNone_oadamp_sNone_d0.25_lr0.001-ver81\n",
            "Train Epoch: 2 [0/25351378 (0%)]\tLoss: 0.723113\n",
            "Train Epoch: 2 [3276800/25351378 (13%)]\tLoss: 0.698163\n",
            "Train Epoch: 2 [6553600/25351378 (26%)]\tLoss: 0.700077\n",
            "Train Epoch: 2 [9830400/25351378 (39%)]\tLoss: 0.693995\n",
            "Train Epoch: 2 [13107200/25351378 (52%)]\tLoss: 0.684364\n",
            "Train Epoch: 2 [16384000/25351378 (65%)]\tLoss: 0.685136\n",
            "Train Epoch: 2 [19660800/25351378 (78%)]\tLoss: 0.691547\n",
            "Train Epoch: 2 [22937600/25351378 (90%)]\tLoss: 0.668713\n",
            "Train Epoch: 2 [0/10839756 (0%)]\tLoss: 0.677930\n",
            "Train Epoch: 2 [3276800/10839756 (30%)]\tLoss: 0.659830\n",
            "Train Epoch: 2 [6553600/10839756 (60%)]\tLoss: 0.653838\n",
            "Train Epoch: 2 [9830400/10839756 (91%)]\tLoss: 0.659974\n",
            "Validation Accuracy = 81.15082560170447%\n",
            "Time taken = 470.0029604434967 secs\n",
            "\n",
            "\n",
            "Saving best model!\n",
            "Model saved at :  /content/cmudrive/IDL/hw1-models-sub/full_Ensemble2_b16384_e15_c32_bnafter_wNone_oadamp_sNone_d0.25_lr0.001-ver81\n",
            "Train Epoch: 3 [0/25351378 (0%)]\tLoss: 0.647191\n",
            "Train Epoch: 3 [3276800/25351378 (13%)]\tLoss: 0.642266\n",
            "Train Epoch: 3 [6553600/25351378 (26%)]\tLoss: 0.647209\n",
            "Train Epoch: 3 [9830400/25351378 (39%)]\tLoss: 0.629495\n",
            "Train Epoch: 3 [13107200/25351378 (52%)]\tLoss: 0.628855\n",
            "Train Epoch: 3 [16384000/25351378 (65%)]\tLoss: 0.632541\n",
            "Train Epoch: 3 [19660800/25351378 (78%)]\tLoss: 0.641759\n",
            "Train Epoch: 3 [22937600/25351378 (90%)]\tLoss: 0.605755\n",
            "Train Epoch: 3 [0/10839756 (0%)]\tLoss: 0.637729\n",
            "Train Epoch: 3 [3276800/10839756 (30%)]\tLoss: 0.635126\n",
            "Train Epoch: 3 [6553600/10839756 (60%)]\tLoss: 0.614271\n",
            "Train Epoch: 3 [9830400/10839756 (91%)]\tLoss: 0.610990\n",
            "Validation Accuracy = 82.11469855937767%\n",
            "Time taken = 503.192351102829 secs\n",
            "\n",
            "\n",
            "Saving best model!\n",
            "Model saved at :  /content/cmudrive/IDL/hw1-models-sub/full_Ensemble2_b16384_e15_c32_bnafter_wNone_oadamp_sNone_d0.25_lr0.001-ver81\n",
            "Train Epoch: 4 [0/25351378 (0%)]\tLoss: 0.629948\n",
            "Train Epoch: 4 [3276800/25351378 (13%)]\tLoss: 0.614595\n",
            "Train Epoch: 4 [6553600/25351378 (26%)]\tLoss: 0.618519\n",
            "Train Epoch: 4 [9830400/25351378 (39%)]\tLoss: 0.609820\n",
            "Train Epoch: 4 [13107200/25351378 (52%)]\tLoss: 0.615502\n",
            "Train Epoch: 4 [16384000/25351378 (65%)]\tLoss: 0.608628\n",
            "Train Epoch: 4 [19660800/25351378 (78%)]\tLoss: 0.604654\n",
            "Train Epoch: 4 [22937600/25351378 (90%)]\tLoss: 0.578184\n",
            "Train Epoch: 4 [0/10839756 (0%)]\tLoss: 0.620740\n",
            "Train Epoch: 4 [3276800/10839756 (30%)]\tLoss: 0.606092\n",
            "Train Epoch: 4 [6553600/10839756 (60%)]\tLoss: 0.593603\n",
            "Train Epoch: 4 [9830400/10839756 (91%)]\tLoss: 0.586946\n",
            "Validation Accuracy = 82.76285473621623%\n",
            "Time taken = 538.9044969081879 secs\n",
            "\n",
            "\n",
            "Saving best model!\n",
            "Model saved at :  /content/cmudrive/IDL/hw1-models-sub/full_Ensemble2_b16384_e15_c32_bnafter_wNone_oadamp_sNone_d0.25_lr0.001-ver81\n",
            "Train Epoch: 5 [0/25351378 (0%)]\tLoss: 0.618730\n",
            "Train Epoch: 5 [3276800/25351378 (13%)]\tLoss: 0.603978\n",
            "Train Epoch: 5 [6553600/25351378 (26%)]\tLoss: 0.600848\n",
            "Train Epoch: 5 [9830400/25351378 (39%)]\tLoss: 0.599161\n",
            "Train Epoch: 5 [13107200/25351378 (52%)]\tLoss: 0.599862\n",
            "Train Epoch: 5 [16384000/25351378 (65%)]\tLoss: 0.586425\n",
            "Train Epoch: 5 [19660800/25351378 (78%)]\tLoss: 0.588589\n",
            "Train Epoch: 5 [22937600/25351378 (90%)]\tLoss: 0.578565\n",
            "Train Epoch: 5 [0/10839756 (0%)]\tLoss: 0.600939\n",
            "Train Epoch: 5 [3276800/10839756 (30%)]\tLoss: 0.586162\n",
            "Train Epoch: 5 [6553600/10839756 (60%)]\tLoss: 0.567857\n",
            "Train Epoch: 5 [9830400/10839756 (91%)]\tLoss: 0.585449\n",
            "Validation Accuracy = 83.1450490736497%\n",
            "Time taken = 573.2847878932953 secs\n",
            "\n",
            "\n",
            "Saving best model!\n",
            "Model saved at :  /content/cmudrive/IDL/hw1-models-sub/full_Ensemble2_b16384_e15_c32_bnafter_wNone_oadamp_sNone_d0.25_lr0.001-ver81\n",
            "Train Epoch: 6 [0/25351378 (0%)]\tLoss: 0.588836\n",
            "Train Epoch: 6 [3276800/25351378 (13%)]\tLoss: 0.581521\n",
            "Train Epoch: 6 [6553600/25351378 (26%)]\tLoss: 0.580889\n",
            "Train Epoch: 6 [9830400/25351378 (39%)]\tLoss: 0.558579\n",
            "Train Epoch: 6 [13107200/25351378 (52%)]\tLoss: 0.590999\n",
            "Train Epoch: 6 [16384000/25351378 (65%)]\tLoss: 0.578045\n",
            "Train Epoch: 6 [19660800/25351378 (78%)]\tLoss: 0.573622\n",
            "Train Epoch: 6 [22937600/25351378 (90%)]\tLoss: 0.574178\n",
            "Train Epoch: 6 [0/10839756 (0%)]\tLoss: 0.592521\n",
            "Train Epoch: 6 [3276800/10839756 (30%)]\tLoss: 0.571925\n",
            "Train Epoch: 6 [6553600/10839756 (60%)]\tLoss: 0.569353\n",
            "Train Epoch: 6 [9830400/10839756 (91%)]\tLoss: 0.571865\n",
            "Validation Accuracy = 83.55299830296424%\n",
            "Time taken = 609.148047208786 secs\n",
            "\n",
            "\n",
            "Saving best model!\n",
            "Model saved at :  /content/cmudrive/IDL/hw1-models-sub/full_Ensemble2_b16384_e15_c32_bnafter_wNone_oadamp_sNone_d0.25_lr0.001-ver81\n",
            "Train Epoch: 7 [0/25351378 (0%)]\tLoss: 0.576397\n",
            "Train Epoch: 7 [3276800/25351378 (13%)]\tLoss: 0.585697\n",
            "Train Epoch: 7 [6553600/25351378 (26%)]\tLoss: 0.580108\n",
            "Train Epoch: 7 [9830400/25351378 (39%)]\tLoss: 0.583450\n",
            "Train Epoch: 7 [13107200/25351378 (52%)]\tLoss: 0.577697\n",
            "Train Epoch: 7 [16384000/25351378 (65%)]\tLoss: 0.577400\n",
            "Train Epoch: 7 [19660800/25351378 (78%)]\tLoss: 0.574618\n",
            "Train Epoch: 7 [22937600/25351378 (90%)]\tLoss: 0.568156\n",
            "Train Epoch: 7 [0/10839756 (0%)]\tLoss: 0.577206\n",
            "Train Epoch: 7 [3276800/10839756 (30%)]\tLoss: 0.564042\n",
            "Train Epoch: 7 [6553600/10839756 (60%)]\tLoss: 0.566456\n",
            "Train Epoch: 7 [9830400/10839756 (91%)]\tLoss: 0.561475\n",
            "Validation Accuracy = 83.82881822723763%\n",
            "Time taken = 645.2896547317505 secs\n",
            "\n",
            "\n",
            "Saving best model!\n",
            "Model saved at :  /content/cmudrive/IDL/hw1-models-sub/full_Ensemble2_b16384_e15_c32_bnafter_wNone_oadamp_sNone_d0.25_lr0.001-ver81\n",
            "Train Epoch: 8 [0/25351378 (0%)]\tLoss: 0.582415\n",
            "Train Epoch: 8 [3276800/25351378 (13%)]\tLoss: 0.568878\n",
            "Train Epoch: 8 [6553600/25351378 (26%)]\tLoss: 0.567050\n",
            "Train Epoch: 8 [9830400/25351378 (39%)]\tLoss: 0.554994\n",
            "Train Epoch: 8 [13107200/25351378 (52%)]\tLoss: 0.562741\n",
            "Train Epoch: 8 [16384000/25351378 (65%)]\tLoss: 0.566497\n",
            "Train Epoch: 8 [19660800/25351378 (78%)]\tLoss: 0.559057\n",
            "Train Epoch: 8 [22937600/25351378 (90%)]\tLoss: 0.565265\n",
            "Train Epoch: 8 [0/10839756 (0%)]\tLoss: 0.574313\n",
            "Train Epoch: 8 [3276800/10839756 (30%)]\tLoss: 0.554999\n",
            "Train Epoch: 8 [6553600/10839756 (60%)]\tLoss: 0.557997\n",
            "Train Epoch: 8 [9830400/10839756 (91%)]\tLoss: 0.546168\n",
            "Validation Accuracy = 84.00471536457366%\n",
            "Time taken = 676.5402462482452 secs\n",
            "\n",
            "\n",
            "Saving best model!\n",
            "Model saved at :  /content/cmudrive/IDL/hw1-models-sub/full_Ensemble2_b16384_e15_c32_bnafter_wNone_oadamp_sNone_d0.25_lr0.001-ver81\n",
            "Train Epoch: 9 [0/25351378 (0%)]\tLoss: 0.560315\n",
            "Train Epoch: 9 [3276800/25351378 (13%)]\tLoss: 0.565217\n",
            "Train Epoch: 9 [6553600/25351378 (26%)]\tLoss: 0.549685\n",
            "Train Epoch: 9 [9830400/25351378 (39%)]\tLoss: 0.556368\n",
            "Train Epoch: 9 [13107200/25351378 (52%)]\tLoss: 0.560923\n",
            "Train Epoch: 9 [16384000/25351378 (65%)]\tLoss: 0.553312\n",
            "Train Epoch: 9 [19660800/25351378 (78%)]\tLoss: 0.557413\n",
            "Train Epoch: 9 [22937600/25351378 (90%)]\tLoss: 0.543887\n",
            "Train Epoch: 9 [0/10839756 (0%)]\tLoss: 0.563483\n",
            "Train Epoch: 9 [3276800/10839756 (30%)]\tLoss: 0.551174\n",
            "Train Epoch: 9 [6553600/10839756 (60%)]\tLoss: 0.549290\n",
            "Train Epoch: 9 [9830400/10839756 (91%)]\tLoss: 0.554470\n",
            "Validation Accuracy = 84.20925772233852%\n",
            "Time taken = 709.5684535503387 secs\n",
            "\n",
            "\n",
            "Saving best model!\n",
            "Model saved at :  /content/cmudrive/IDL/hw1-models-sub/full_Ensemble2_b16384_e15_c32_bnafter_wNone_oadamp_sNone_d0.25_lr0.001-ver81\n",
            "Train Epoch: 10 [0/25351378 (0%)]\tLoss: 0.552090\n",
            "Train Epoch: 10 [3276800/25351378 (13%)]\tLoss: 0.531297\n",
            "Train Epoch: 10 [6553600/25351378 (26%)]\tLoss: 0.546795\n",
            "Train Epoch: 10 [9830400/25351378 (39%)]\tLoss: 0.562064\n",
            "Train Epoch: 10 [13107200/25351378 (52%)]\tLoss: 0.553603\n",
            "Train Epoch: 10 [16384000/25351378 (65%)]\tLoss: 0.539293\n",
            "Train Epoch: 10 [19660800/25351378 (78%)]\tLoss: 0.549604\n",
            "Train Epoch: 10 [22937600/25351378 (90%)]\tLoss: 0.541836\n",
            "Train Epoch: 10 [0/10839756 (0%)]\tLoss: 0.561216\n",
            "Train Epoch: 10 [3276800/10839756 (30%)]\tLoss: 0.556308\n",
            "Train Epoch: 10 [6553600/10839756 (60%)]\tLoss: 0.530994\n",
            "Train Epoch: 10 [9830400/10839756 (91%)]\tLoss: 0.535520\n",
            "Validation Accuracy = 84.37601935694319%\n",
            "Time taken = 745.138778924942 secs\n",
            "\n",
            "\n",
            "Saving best model!\n",
            "Model saved at :  /content/cmudrive/IDL/hw1-models-sub/full_Ensemble2_b16384_e15_c32_bnafter_wNone_oadamp_sNone_d0.25_lr0.001-ver81\n",
            "Train Epoch: 11 [0/25351378 (0%)]\tLoss: 0.560575\n",
            "Train Epoch: 11 [3276800/25351378 (13%)]\tLoss: 0.549924\n",
            "Train Epoch: 11 [6553600/25351378 (26%)]\tLoss: 0.543360\n",
            "Train Epoch: 11 [9830400/25351378 (39%)]\tLoss: 0.549661\n",
            "Train Epoch: 11 [13107200/25351378 (52%)]\tLoss: 0.543984\n",
            "Train Epoch: 11 [16384000/25351378 (65%)]\tLoss: 0.549510\n",
            "Train Epoch: 11 [19660800/25351378 (78%)]\tLoss: 0.553321\n",
            "Train Epoch: 11 [22937600/25351378 (90%)]\tLoss: 0.548756\n",
            "Train Epoch: 11 [0/10839756 (0%)]\tLoss: 0.533416\n",
            "Train Epoch: 11 [3276800/10839756 (30%)]\tLoss: 0.549785\n",
            "Train Epoch: 11 [6553600/10839756 (60%)]\tLoss: 0.540519\n",
            "Train Epoch: 11 [9830400/10839756 (91%)]\tLoss: 0.522854\n",
            "Validation Accuracy = 84.53483258804148%\n",
            "Time taken = 777.3768918514252 secs\n",
            "\n",
            "\n",
            "Saving best model!\n",
            "Model saved at :  /content/cmudrive/IDL/hw1-models-sub/full_Ensemble2_b16384_e15_c32_bnafter_wNone_oadamp_sNone_d0.25_lr0.001-ver81\n",
            "Train Epoch: 12 [0/25351378 (0%)]\tLoss: 0.547640\n",
            "Train Epoch: 12 [3276800/25351378 (13%)]\tLoss: 0.527445\n",
            "Train Epoch: 12 [6553600/25351378 (26%)]\tLoss: 0.532318\n",
            "Train Epoch: 12 [9830400/25351378 (39%)]\tLoss: 0.542869\n",
            "Train Epoch: 12 [13107200/25351378 (52%)]\tLoss: 0.536609\n",
            "Train Epoch: 12 [16384000/25351378 (65%)]\tLoss: 0.529666\n",
            "Train Epoch: 12 [19660800/25351378 (78%)]\tLoss: 0.517592\n",
            "Train Epoch: 12 [22937600/25351378 (90%)]\tLoss: 0.534693\n",
            "Train Epoch: 12 [0/10839756 (0%)]\tLoss: 0.541840\n",
            "Train Epoch: 12 [3276800/10839756 (30%)]\tLoss: 0.545742\n",
            "Train Epoch: 12 [6553600/10839756 (60%)]\tLoss: 0.539466\n",
            "Train Epoch: 12 [9830400/10839756 (91%)]\tLoss: 0.521966\n",
            "Validation Accuracy = 84.66030381482078%\n",
            "Time taken = 812.6404557228088 secs\n",
            "\n",
            "\n",
            "Saving best model!\n",
            "Model saved at :  /content/cmudrive/IDL/hw1-models-sub/full_Ensemble2_b16384_e15_c32_bnafter_wNone_oadamp_sNone_d0.25_lr0.001-ver81\n",
            "Train Epoch: 13 [0/25351378 (0%)]\tLoss: 0.548385\n",
            "Train Epoch: 13 [3276800/25351378 (13%)]\tLoss: 0.536046\n",
            "Train Epoch: 13 [6553600/25351378 (26%)]\tLoss: 0.540641\n",
            "Train Epoch: 13 [9830400/25351378 (39%)]\tLoss: 0.548678\n",
            "Train Epoch: 13 [13107200/25351378 (52%)]\tLoss: 0.542123\n",
            "Train Epoch: 13 [16384000/25351378 (65%)]\tLoss: 0.539121\n",
            "Train Epoch: 13 [19660800/25351378 (78%)]\tLoss: 0.534439\n",
            "Train Epoch: 13 [22937600/25351378 (90%)]\tLoss: 0.546474\n",
            "Train Epoch: 13 [0/10839756 (0%)]\tLoss: 0.540583\n",
            "Train Epoch: 13 [3276800/10839756 (30%)]\tLoss: 0.543350\n",
            "Train Epoch: 13 [6553600/10839756 (60%)]\tLoss: 0.530162\n",
            "Train Epoch: 13 [9830400/10839756 (91%)]\tLoss: 0.508292\n",
            "Validation Accuracy = 84.75656207806365%\n",
            "Time taken = 847.3039481639862 secs\n",
            "\n",
            "\n",
            "Saving best model!\n",
            "Model saved at :  /content/cmudrive/IDL/hw1-models-sub/full_Ensemble2_b16384_e15_c32_bnafter_wNone_oadamp_sNone_d0.25_lr0.001-ver81\n",
            "Train Epoch: 14 [0/25351378 (0%)]\tLoss: 0.537297\n",
            "Train Epoch: 14 [3276800/25351378 (13%)]\tLoss: 0.525445\n",
            "Train Epoch: 14 [6553600/25351378 (26%)]\tLoss: 0.535591\n",
            "Train Epoch: 14 [9830400/25351378 (39%)]\tLoss: 0.513330\n",
            "Train Epoch: 14 [13107200/25351378 (52%)]\tLoss: 0.529611\n",
            "Train Epoch: 14 [16384000/25351378 (65%)]\tLoss: 0.535840\n",
            "Train Epoch: 14 [19660800/25351378 (78%)]\tLoss: 0.531710\n",
            "Train Epoch: 14 [22937600/25351378 (90%)]\tLoss: 0.516425\n",
            "Train Epoch: 14 [0/10839756 (0%)]\tLoss: 0.534036\n",
            "Train Epoch: 14 [3276800/10839756 (30%)]\tLoss: 0.531966\n",
            "Train Epoch: 14 [6553600/10839756 (60%)]\tLoss: 0.526168\n",
            "Train Epoch: 14 [9830400/10839756 (91%)]\tLoss: 0.507840\n",
            "Validation Accuracy = 84.85586550888364%\n",
            "Time taken = 881.2983770370483 secs\n",
            "\n",
            "\n",
            "Saving best model!\n",
            "Model saved at :  /content/cmudrive/IDL/hw1-models-sub/full_Ensemble2_b16384_e15_c32_bnafter_wNone_oadamp_sNone_d0.25_lr0.001-ver81\n",
            "Train Epoch: 15 [0/25351378 (0%)]\tLoss: 0.549002\n",
            "Train Epoch: 15 [3276800/25351378 (13%)]\tLoss: 0.521267\n",
            "Train Epoch: 15 [6553600/25351378 (26%)]\tLoss: 0.525119\n",
            "Train Epoch: 15 [9830400/25351378 (39%)]\tLoss: 0.533166\n",
            "Train Epoch: 15 [13107200/25351378 (52%)]\tLoss: 0.524769\n",
            "Train Epoch: 15 [16384000/25351378 (65%)]\tLoss: 0.536555\n",
            "Train Epoch: 15 [19660800/25351378 (78%)]\tLoss: 0.507851\n",
            "Train Epoch: 15 [22937600/25351378 (90%)]\tLoss: 0.536520\n",
            "Train Epoch: 15 [0/10839756 (0%)]\tLoss: 0.550361\n",
            "Train Epoch: 15 [3276800/10839756 (30%)]\tLoss: 0.523551\n",
            "Train Epoch: 15 [6553600/10839756 (60%)]\tLoss: 0.515073\n",
            "Train Epoch: 15 [9830400/10839756 (91%)]\tLoss: 0.523586\n",
            "Validation Accuracy = 84.94954312163742%\n",
            "Time taken = 915.6978788375854 secs\n",
            "\n",
            "\n",
            "Saving best model!\n",
            "Model saved at :  /content/cmudrive/IDL/hw1-models-sub/full_Ensemble2_b16384_e15_c32_bnafter_wNone_oadamp_sNone_d0.25_lr0.001-ver81\n",
            "\n",
            "-------------------------Training Complete!------------------------\n",
            "Model saved at :  /content/cmudrive/IDL/hw1-models-sub/full_Ensemble2_b16384_e15_c32_bnafter_wNone_oadamp_sNone_d0.25_lr0.001-ver81\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<br/>Waiting for W&B process to finish, PID 3084... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "132bee68595c4ff1a8af4e8b2ff72f2e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "VBox(children=(Label(value=' 0.09MB of 0.09MB uploaded (0.00MB deduped)\\r'), FloatProgress(value=1.0, max=1.0)â¦"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<style>\n",
              "    table.wandb td:nth-child(1) { padding: 0 10px; text-align: right }\n",
              "    .wandb-row { display: flex; flex-direction: row; flex-wrap: wrap; width: 100% }\n",
              "    .wandb-col { display: flex; flex-direction: column; flex-basis: 100%; flex: 1; padding: 10px; }\n",
              "    </style>\n",
              "<div class=\"wandb-row\"><div class=\"wandb-col\">\n",
              "<h3>Run history:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>âââââââââââââââ</td></tr><tr><td>Training Loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr><tr><td>Validation Loss</td><td>ââââââââââââââââââââââââââââââââââââââââ</td></tr></table><br/></div><div class=\"wandb-col\">\n",
              "<h3>Run summary:</h3><br/><table class=\"wandb\"><tr><td>Accuracy</td><td>84.94954</td></tr><tr><td>Training Loss</td><td>0.52359</td></tr><tr><td>Validation Loss</td><td>0.45226</td></tr></table>\n",
              "</div></div>\n",
              "Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 1 other file(s)\n",
              "<br/>Synced <strong style=\"color:#cdcd00\">fluent-snowball-13</strong>: <a href=\"https://wandb.ai/nefario7/hw1-submission/runs/3gezztp5\" target=\"_blank\">https://wandb.ai/nefario7/hw1-submission/runs/3gezztp5</a><br/>\n",
              "Find logs at: <code></code><br/>\n"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abRGdUYPx7Gp"
      },
      "source": [
        "## Sweep\n",
        "[wandb Sweep](https://docs.wandb.ai/guides/sweeps)"
      ],
      "id": "abRGdUYPx7Gp"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dHCRZruhx8Yl"
      },
      "outputs": [],
      "source": [
        "sweep_config = {\n",
        "  \"name\" : \"hw1-sweep\",\n",
        "  \"method\": \"bayes\", \n",
        "  \"parameters\": {\n",
        "    \"optimizer\": {\n",
        "      \"distribution\": \"categorical\", \n",
        "      \"values\": [\n",
        "        \"sgdn\", \n",
        "        \"adam\"\n",
        "      ]\n",
        "    }, \n",
        "    \"scheduler\": {\n",
        "      \"distribution\": \"categorical\", \n",
        "      \"values\": [\n",
        "        \"rlrop\", \n",
        "        \"exp\"\n",
        "      ]\n",
        "    }, \n",
        "    \"bn\": {\n",
        "      \"distribution\": \"categorical\", \n",
        "      \"values\": [\n",
        "        \"after\", \n",
        "        \"before\"\n",
        "      ]\n",
        "    },  \n",
        "    \"epoch\": {\n",
        "      \"max\": 20, \n",
        "      \"distribution\": \"int_uniform\", \n",
        "      \"min\": 5\n",
        "    }, \n",
        "    \"lr\": {\n",
        "      \"max\": 0.02, \n",
        "      \"distribution\": \"uniform\", \n",
        "      \"min\": 0.0005\n",
        "    }, \n",
        "    \"batch_size\": {\n",
        "      \"max\": 131072, \n",
        "      \"distribution\": \"int_uniform\", \n",
        "      \"min\": 2048\n",
        "    }, \n",
        "    \"context\": {\n",
        "      \"max\": 64, \n",
        "      \"distribution\": \"int_uniform\", \n",
        "      \"min\": 8\n",
        "    }\n",
        "  }\n",
        "}\n",
        "\n",
        "sweep_id = wandb.sweep(sweep_config)\n",
        "def train():\n",
        "    with wandb.init() as run:\n",
        "        config = wandb.config\n",
        "        model = make_model(config)\n",
        "        for epoch in range(config[\"epochs\"]):\n",
        "            loss = model.fit()  # your model training code here\n",
        "            wandb.log({\"loss\": loss, \"epoch\": epoch})\n",
        "\n",
        "count = 5 # number of runs to execute\n",
        "wandb.agent(sweep_id, function=train, count=count)"
      ],
      "id": "dHCRZruhx8Yl"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sAE0sHT3Z9UX"
      },
      "source": [
        "## Submission"
      ],
      "id": "sAE0sHT3Z9UX"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ealq3nfZ8y0"
      },
      "outputs": [],
      "source": [
        "import csv, yaml\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torchsummary import summary\n",
        "from sklearn.metrics import accuracy_score\n",
        "import os, datetime\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.ensemble import VotingClassifier\n",
        "\n",
        "class Network(torch.nn.Module):\n",
        "    def __init__(self, arch, context=0, drop=0.1):\n",
        "        super(Network, self).__init__()\n",
        "        c = (1 + 2 * context)\n",
        "        INPUT_SIZE = c * 13\n",
        "        NUM_CLASSES = 40\n",
        "\n",
        "        layers = []\n",
        "        sizes = [INPUT_SIZE] + arch + [NUM_CLASSES]\n",
        "        \n",
        "        print(\"Network Architecture\")\n",
        "        print(f\"No. of hidden layers  = {len(sizes) - 2}, Max. Width = {max(sizes)}\")\n",
        "        for i in range(len(sizes) - 1):\n",
        "            layers.append(nn.Linear(sizes[i], sizes[i+1]))\n",
        "            if sizes[i+1] != NUM_CLASSES:\n",
        "                layers.append(nn.ReLU())\n",
        "                layers.append(nn.BatchNorm1d(num_features = sizes[i+1]))\n",
        "                layers.append(nn.Dropout(drop))\n",
        "        \n",
        "        self.classifier = nn.Sequential(*layers)\n",
        "\n",
        "    def forward(self, A0):\n",
        "        x = self.classifier(A0)\n",
        "        return x\n",
        "\n",
        "class SubmissionSamples(torch.utils.data.Dataset):\n",
        "    def __init__(self, data_path, csv_path, sample=20000, shuffle=False, partition=\"test-clean\"):\n",
        "        # sample represent how many npy files will be preloaded for one __getitem__ call\n",
        "        self.sample = sample \n",
        "        self.X_dir = data_path + \"/\" + partition + \"/mfcc/\"\n",
        "        self.X_names = os.listdir(self.X_dir)\n",
        "\n",
        "        if csv_path:\n",
        "            self.X_names = list(pd.read_csv(csv_path).file)\n",
        "        \n",
        "        self.length = len(self.X_names)\n",
        "        self.PHONEMES = [\n",
        "            'SIL',   'AA',    'AE',    'AH',    'AO',    'AW',    'AY',  \n",
        "            'B',     'CH',    'D',     'DH',    'EH',    'ER',    'EY',\n",
        "            'F',     'G',     'HH',    'IH',    'IY',    'JH',    'K',\n",
        "            'L',     'M',     'N',     'NG',    'OW',    'OY',    'P',\n",
        "            'R',     'S',     'SH',    'T',     'TH',    'UH',    'UW',\n",
        "            'V',     'W',     'Y',     'Z',     'ZH',    '<sos>', '<eos>']\n",
        "\n",
        "    def __len__(self):\n",
        "        return int(np.ceil(self.length / self.sample))\n",
        "        \n",
        "    def __getitem__(self, i):\n",
        "        sample_range = range(i*self.sample, min((i+1)*self.sample, self.length))\n",
        "        \n",
        "        X, Y = [], []\n",
        "        for j in sample_range:\n",
        "            X_path = self.X_dir + self.X_names[j]\n",
        "            X_data = np.load(X_path)\n",
        "            X_data = (X_data - X_data.mean(axis=0))/X_data.std(axis=0)\n",
        "            X.append(X_data)\n",
        "\n",
        "        X = np.concatenate(X)\n",
        "        return X\n",
        "\n",
        "class SubmissionItems(torch.utils.data.Dataset):\n",
        "    def __init__(self, X, context = 0):   \n",
        "        self.length  = X.shape[0]\n",
        "        self.context = context\n",
        "\n",
        "        if context != 0:\n",
        "            X = np.pad(X, ((context,context), (0,0)), 'constant', constant_values=(0,0))\n",
        "        self.X = X\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "        \n",
        "    def __getitem__(self, i):\n",
        "        if self.context == 0:\n",
        "            xx = self.X[i].flatten()\n",
        "        else:\n",
        "            xx = self.X[i:(i + 2 * self.context + 1)].flatten()\n",
        "        return xx\n",
        "\n",
        "class SubmissionInference():\n",
        "    def __init__(self, data_path, csv_path):\n",
        "        self.device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "        self.drive_dir = r'/content/cmudrive/IDL'\n",
        "\n",
        "        self.data_path = data_path\n",
        "        self.order_csv_path = csv_path\n",
        "        self.test_samples = SubmissionSamples(data_path = self.data_path, csv_path=self.order_csv_path)\n",
        "\n",
        "    def __get_labels(self, imodel, iargs):\n",
        "        imodel.eval()\n",
        "        labels = []\n",
        "        print(f\"Context = {iargs['context']} | Batch Size = {iargs['batch_size']} | Arch = {iargs['arch']}\")\n",
        "        with torch.no_grad():\n",
        "            for i in range(len(self.test_samples)):\n",
        "                X = self.test_samples[i]\n",
        "                test_items = SubmissionItems(X, context=iargs['context'])\n",
        "                test_loader = torch.utils.data.DataLoader(test_items, batch_size=iargs['batch_size'], num_workers=2, pin_memory=True, shuffle=False)\n",
        "\n",
        "                for data in tqdm(test_loader):\n",
        "                    data = data.float().to(self.device)              \n",
        "                    output = imodel(data)\n",
        "                    y = torch.argmax(output, axis=1)\n",
        "                    labels.extend(y.tolist())\n",
        "        return labels\n",
        "\n",
        "    def __load_model(self, model_name, model_type): \n",
        "        meta_path = os.path.join(self.drive_dir,  model_type, model_name, 'model_parameters.yaml')\n",
        "        with open(meta_path, 'r') as meta:\n",
        "            args = yaml.safe_load(meta)\n",
        "\n",
        "        model_path = os.path.join(self.drive_dir, model_type, model_name, 'model.pth')\n",
        "        model = Network(args[\"arch\"], args['context'], args['drop']).to(self.device)\n",
        "        # summary(model)\n",
        "        model.load_state_dict(torch.load(model_path))\n",
        "        return model, args\n",
        "\n",
        "    def simple_inference(self, model_name, model_type):\n",
        "        print(\"Running inference...\")\n",
        "        self.timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "        model, args = self.__load_model(model_name, model_type)\n",
        "        labels = self.__get_labels(model, args)\n",
        "        \n",
        "        return labels\n",
        "\n",
        "    def ensemble_inference(self, model_names, model_type):\n",
        "        print(\"Running ensembled inference...\")\n",
        "        self.timestamp = datetime.datetime.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
        "\n",
        "        prelim_labels = []\n",
        "        for name in model_names:\n",
        "            print(\"\\n\\n\\tModel : \", name)\n",
        "            model, args = self.__load_model(name, model_type)\n",
        "            prelim_labels.append(self.__get_labels(model, args))\n",
        "\n",
        "        accs = [86.146, 85.79, 84.95]\n",
        "        w = accs / np.sum(accs)\n",
        "\n",
        "        print(\"Combining predictions...\")\n",
        "        labels_df = pd.DataFrame(prelim_labels)\n",
        "        labels_df = labels_df.transpose()\n",
        "        ensembled_labels = labels_df.mode(axis=1, dropna=False).iloc[:, 0].tolist()\n",
        "        # ensembled_labels = np.where((df.iloc[:,1] == df.iloc[:, 2]), df.iloc[:, 1], df.iloc[:, 0]).tolist()\n",
        "\n",
        "        return labels_df, ensembled_labels\n",
        "\n",
        "    def generate_submission(self, save_path, labels): \n",
        "        sub_dir = os.path.join(self.drive_dir, save_path + self.timestamp)\n",
        "        try:\n",
        "            os.mkdir(sub_dir)\n",
        "        except:\n",
        "            print(\"Couldn't create folder for submission.csv\")\n",
        "            \n",
        "        sub_path = os.path.join(sub_dir, 'submission.csv')\n",
        "\n",
        "        with open(sub_path, 'w') as f:\n",
        "            csvwrite = csv.writer(f)\n",
        "            csvwrite.writerow(['id', 'label'])\n",
        "            for i in range(len(labels)):\n",
        "                csvwrite.writerow([i, labels[i]])\n",
        "\n",
        "        print(f\"File saved at : {sub_path}\")\n",
        "        return sub_path\n"
      ],
      "id": "2ealq3nfZ8y0"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oMh9pfZtd22K",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 797
        },
        "outputId": "a370fbee-1632-4e6e-ceb3-4c0e427d78f1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Running ensembled inference...\n",
            "\n",
            "\n",
            "\tModel :  full_Finale_b16384_e25_c16_bnafter_wNone_oadamp_sNone_d0.25_lr0.001-ver81\n",
            "Network Architecture\n",
            "No. of hidden layers  = 7, Max. Width = 4096\n",
            "Context = 16 | Batch Size = 16384 | Arch = [4096, 2048, 2048, 2048, 1024, 512, 256]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|ââââââââââ| 119/119 [00:13<00:00,  9.13it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\tModel :  full_Ensemble1_b16384_e20_c16_bnafter_wNone_oadamp_sNone_d0.25_lr0.001-ver48\n",
            "Network Architecture\n",
            "No. of hidden layers  = 8, Max. Width = 4096\n",
            "Context = 16 | Batch Size = 16384 | Arch = [512, 1024, 2048, 4096, 2048, 1024, 512, 256]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|ââââââââââ| 119/119 [00:13<00:00,  8.79it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "\tModel :  full_Ensemble2_b16384_e15_c32_bnafter_wNone_oadamp_sNone_d0.25_lr0.001-ver81\n",
            "Network Architecture\n",
            "No. of hidden layers  = 8, Max. Width = 1024\n",
            "Context = 32 | Batch Size = 16384 | Arch = [1024, 1024, 1024, 1024, 1024, 1024, 1024, 1024]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|ââââââââââ| 119/119 [00:10<00:00, 11.51it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Combining predictions...\n",
            "File saved at : /content/cmudrive/IDL/hw1-submission/2022-02-13_06-22-00/submission.csv\n",
            "Preview of submission.csv\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-bcfdb71d-2f78-4615-abb3-1d85d5eae868\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>5</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>6</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>7</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>8</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>9</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bcfdb71d-2f78-4615-abb3-1d85d5eae868')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bcfdb71d-2f78-4615-abb3-1d85d5eae868 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bcfdb71d-2f78-4615-abb3-1d85d5eae868');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "   id  label\n",
              "0   0    0.0\n",
              "1   1    0.0\n",
              "2   2    0.0\n",
              "3   3    0.0\n",
              "4   4    0.0\n",
              "5   5    0.0\n",
              "6   6    0.0\n",
              "7   7    0.0\n",
              "8   8    0.0\n",
              "9   9    0.0"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ],
      "source": [
        "model_name = r'full_Finale_b16384_e25_c16_bnafter_wNone_oadamp_sNone_d0.25_lr0.001-ver81'\n",
        "models = [\n",
        "          r'full_Finale_b16384_e25_c16_bnafter_wNone_oadamp_sNone_d0.25_lr0.001-ver81',\n",
        "          r'full_Ensemble1_b16384_e20_c16_bnafter_wNone_oadamp_sNone_d0.25_lr0.001-ver48',\n",
        "          r'full_Ensemble2_b16384_e15_c32_bnafter_wNone_oadamp_sNone_d0.25_lr0.001-ver81'\n",
        "          ]\n",
        "model_type = r'hw1-models-sub'\n",
        "data_path = r'/content/hw1-data/hw1p2_student_data'\n",
        "csv_path = r'/content/hw1-data/test_order.csv'\n",
        "sub_path = r'hw1-submission/'\n",
        "\n",
        "inference = SubmissionInference(data_path, csv_path)\n",
        "\n",
        "# Simple and Ensemble Inference\n",
        "# labels = inference.simple_inference(model_name, model_type)\n",
        "labels_df, labels = inference.ensemble_inference(models, model_type)\n",
        "\n",
        "submission_path = inference.generate_submission(sub_path, labels)\n",
        "print(f\"Preview of submission.csv\")\n",
        "df = pd.read_csv(submission_path)\n",
        "df.head(10)"
      ],
      "id": "oMh9pfZtd22K"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "moZJfg2VakUk",
        "outputId": "ce30f8b6-2b8d-4fb5-b13c-f6e8fe4341e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/cmudrive/IDL/hw1-submission/2022-02-13_06-22-00/submission.csv\n",
            "100% 24.2M/24.2M [00:00<00:00, 58.8MB/s]\n",
            "Successfully submitted to Frame-Level Speech Recognition"
          ]
        }
      ],
      "source": [
        "print(submission_path)\n",
        "! kaggle competitions submit -c 11-785-s22-hw1p2 -f $submission_path -m \"BlSubmission\""
      ],
      "id": "moZJfg2VakUk"
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [
        "pEEirl65cINF",
        "27RRsooJcNMM",
        "9vFFGI9FcPd8",
        "uc3cpN3gcSyy",
        "3I_Ds0n8LBTd",
        "abRGdUYPx7Gp"
      ],
      "machine_shape": "hm",
      "name": "hw1-pt2-updated",
      "provenance": [],
      "include_colab_link": true
    },
    "interpreter": {
      "hash": "239d5711fd35d2bb9bad2d5ca41e22b79107b4494fe73df9033b517b748af271"
    },
    "kernelspec": {
      "display_name": "PyTorch (3.8)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.2"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "132bee68595c4ff1a8af4e8b2ff72f2e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "VBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "VBoxView",
            "_dom_classes": [],
            "_model_name": "VBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_ad3e230a109a41a3b70014c5e822b22a",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3c4ed1d3e9a0417592d804cf83bcd0f7",
              "IPY_MODEL_fd9d47d8f6fe4cf4afbc9a8074c005dc"
            ]
          }
        },
        "ad3e230a109a41a3b70014c5e822b22a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3c4ed1d3e9a0417592d804cf83bcd0f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "LabelModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "LabelView",
            "style": "IPY_MODEL_9f4290771ab7487491665360bb4c55be",
            "_dom_classes": [],
            "description": "",
            "_model_name": "LabelModel",
            "placeholder": "â",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.79MB of 1.79MB uploaded (0.00MB deduped)\r",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_6112d23b1ebd4e28a7af8493edf31650"
          }
        },
        "fd9d47d8f6fe4cf4afbc9a8074c005dc": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_5d2d8c51ae174ec0ada0137c802073e4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 1,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3104862bb0ee41478b5d374455603630"
          }
        },
        "9f4290771ab7487491665360bb4c55be": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "6112d23b1ebd4e28a7af8493edf31650": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5d2d8c51ae174ec0ada0137c802073e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3104862bb0ee41478b5d374455603630": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}